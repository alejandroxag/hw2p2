# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/face_class_ver.ipynb (unless otherwise specified).

__all__ = ['main']

# Cell
# imports
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import torchvision
from PIL import Image
from torch.nn.functional import cosine_similarity, adaptive_avg_pool2d
from torch.optim import Adam, SGD
from torch.optim.lr_scheduler import StepLR
from sklearn.metrics import roc_auc_score
import pandas as pd
from functools import partial
from hyperopt import fmin, tpe, hp, Trials, STATUS_OK
from hyperopt.pyll.base import scope
import json
from datetime import datetime
import os
import time

# from datasets import FaceClassificationDataset, FaceVerificationDataset
# from losses import CenterLoss
# from models.mobilenet import *
# from models.resnet import *
# from hyperoptimization import fit_predict
from .datasets import FaceClassificationDataset, FaceVerificationDataset
from .losses import CenterLoss
from .models.mobilenet import *
from .models.resnet import *
from .hyperoptimization import fit_predict

# Cell
def main(model, sample_size=None, max_evals=20):

    # Hyperparameters space
    space = {'model': hp.choice(label='model', options=[model]),
             'in_channels': hp.choice(label='in_channels', options=[3]),
            #  'n_classes': hp.choice(label='n_classes', options=[4000]),
             'batch_size': scope.int(hp.choice(label='batch_size', options=[16])),
             'lr': hp.loguniform(label='lr', low=np.log(5e-3), high=np.log(5e-2)),
             'lr_decay': hp.choice(label='lr_decay', options=[0.5]),
             'n_lr_decay_steps': hp.choice(label='n_lr_decay_steps', options=[3]),
             'center_loss': hp.choice(label='center_loss', options=[True]),
             'lr_cl': hp.loguniform(label='lr_cl', low=np.log(5e-3), high=np.log(2e-1)),
             'alpha_cl': hp.choice(label='alpha_cl', options=[0.01,0.1,1]),
             'n_epochs': hp.choice(label='n_epochs', options=[5]),
             'eval_steps': scope.int(hp.choice(label='eval_steps', options=[4])),}

    if sample_size==None:
        space['n_classes'] = hp.choice(label='n_classes', options=[4000])
    else:
        space['n_classes'] = hp.choice(label='n_classes', options=[sample_size])

    # Hyperparameters search
    trials = Trials()
    fmin_objective = partial(fit_predict, trials=trials, verbose=True, sample_size=sample_size)
    best = fmin(fmin_objective, space=space, algo=tpe.suggest, max_evals=max_evals, trials=trials)

    keys = ['loss','val_c_loss','train_c_acc','val_c_acc','val_v_acc','run_time','trajectories']

    best_class = trials.results[np.argmax([r['val_c_acc'] for r in trials.results])]
    best_class_res_dict = {key: best_class[key] for key in keys}
    best_class_model = best_class['model']
    best_class_mc = best_class['mc']
    best_class_time_stamp = best_class['time_stamp']

    s = 'hw2p2' + '_' + best_class_time_stamp
    filename = f'./results/{s}.pth'

    json_mc = json.dumps(best_class_mc)
    with open(f'./results/mc_{best_class_time_stamp}.json', 'w') as bfm:
        bfm.write(json_mc)
    json_res = json.dumps(best_class_res_dict)
    with open(f'./results/res_dict_{best_class_time_stamp}.json', 'w') as bfm:
        bfm.write(json_res)

    torch.save(best_class_model.model.state_dict(), filename)

    best_ver = trials.results[np.argmax([r['val_v_acc'] for r in trials.results])]
    best_ver_res_dict = {key: best_ver[key] for key in keys}
    best_ver_model = best_ver['model']
    best_ver_mc = best_ver['mc']
    best_ver_time_stamp = best_ver['time_stamp']

    s = 'hw2p2' + '_' + best_ver_time_stamp
    filename = f'./results/{s}.pth'

    json_mc = json.dumps(best_ver_mc)
    with open(f'./results/mc_{best_ver_time_stamp}.json', 'w') as bfm:
        bfm.write(json_mc)
    json_res = json.dumps(best_ver_res_dict)
    with open(f'./results/res_dict_{best_ver_time_stamp}.json', 'w') as bfm:
        bfm.write(json_res)

    torch.save(best_ver_model.model.state_dict(), filename)


# Cell
if __name__ == "__main__":
    main(model='resnet18', sample_size=20, max_evals=5)