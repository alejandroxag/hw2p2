{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp hyperoptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters optimization\n",
    "\n",
    ">Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# imports\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from torch.nn.functional import cosine_similarity, adaptive_avg_pool2d\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "from hyperopt.pyll.base import scope\n",
    "import json\n",
    "from datetime import datetime\n",
    "import os\n",
    "import time\n",
    "\n",
    "from datasets import FaceClassificationDataset, FaceVerificationDataset\n",
    "from losses import CenterLoss\n",
    "from models import _BottleNeck, _MobileNetV2, MobileNetV2\n",
    "# from axa_hw2p2.datasets import FaceClassificationDataset, FaceVerificationDataset\n",
    "# from axa_hw2p2.losses import CenterLoss\n",
    "# from axa_hw2p2.models import _BottleNeck, _MobileNetV2, MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def fit_predict(mc, verbose, trials=None):\n",
    "    print(f'\\nCurrent directory: {os.getcwd()}\\n')\n",
    "    now = datetime.now().strftime(\"%d-%m-%y_%H-%M-%S\")\n",
    "    print(now)\n",
    "\n",
    "    start_time = time.time()\n",
    "    print('='*26)\n",
    "    print(pd.Series(mc))\n",
    "    print('='*26+'\\n')\n",
    "\n",
    "    num_workers = 8 if torch.cuda.is_available() else 0\n",
    "\n",
    "    np.random.seed(1)\n",
    "    sample_train = np.array(range(100))\n",
    "    sample_val_c = list(range(25))\n",
    "    sample_val_c = np.array([sample_train[i] for i in sample_val_c])\n",
    "    sample_val_v = np.array(range(25))\n",
    "\n",
    "    train_dataset = FaceClassificationDataset(sample_train, mode='train')\n",
    "    val_c_dataset = FaceClassificationDataset(sample_val_c, mode='val')\n",
    "    val_v_dataset = FaceVerificationDataset(sample_val_v, mode='val')\n",
    "\n",
    "    # train_dataset = FaceClassificationDataset(mode='train')\n",
    "    # val_c_dataset = FaceClassificationDataset(mode='val')\n",
    "    # val_v_dataset = FaceVerificationDataset(mode='val')\n",
    "\n",
    "    # train_loader = DataLoader(train_dataset, \n",
    "    #                           shuffle=True, \n",
    "    #                           batch_size=mc['batch_size'], \n",
    "    #                           drop_last=True)\n",
    "\n",
    "    # val_c_loader = DataLoader(val_c_dataset, \n",
    "    #                           shuffle=False, \n",
    "    #                           batch_size=1, \n",
    "    #                           drop_last=True)\n",
    "\n",
    "    # val_v_loader = DataLoader(val_v_dataset, \n",
    "    #                           shuffle=False, \n",
    "    #                           batch_size=1, \n",
    "    #                           drop_last=True)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, \n",
    "                              shuffle=True, \n",
    "                              batch_size=mc['batch_size'], \n",
    "                              num_workers=num_workers, \n",
    "                              pin_memory=True,\n",
    "                              drop_last=True)\n",
    "\n",
    "    val_c_loader = DataLoader(val_c_dataset, \n",
    "                              shuffle=False, \n",
    "                              batch_size=mc['batch_size'], \n",
    "                              num_workers=num_workers, \n",
    "                              pin_memory=True,\n",
    "                              drop_last=True)\n",
    "\n",
    "    val_v_loader = DataLoader(val_v_dataset, \n",
    "                              shuffle=False, \n",
    "                              batch_size=mc['batch_size'], \n",
    "                              num_workers=num_workers, \n",
    "                              pin_memory=True,\n",
    "                              drop_last=True)\n",
    "\n",
    "    model = MobileNetV2(n_in_ch_bn=mc['n_in_ch_bn'],\n",
    "                        ls_out_ch_bn=mc['ls_out_ch_bn'],\n",
    "                        ls_n_rep_bn=mc['ls_n_rep_bn'],\n",
    "                        ls_stride_bn=mc['ls_stride_bn'],\n",
    "                        ls_exp_fct_t_bn=mc['ls_exp_fct_t_bn'],\n",
    "                        n_embeddings=mc['n_embeddings'],\n",
    "                        n_classes=mc['n_classes'],\n",
    "                        lr=mc['lr'],\n",
    "                        lr_decay=mc['lr_decay'],\n",
    "                        n_lr_decay_steps=mc['n_lr_decay_steps'],\n",
    "                        center_loss=mc['center_loss'],\n",
    "                        lr_cl=mc['lr_cl'],\n",
    "                        alpha_cl=mc['alpha_cl'],\n",
    "                        n_epochs=mc['n_epochs'],\n",
    "                        eval_steps=mc['eval_steps'])\n",
    "\n",
    "    model.fit(train_loader=train_loader, \n",
    "              val_c_loader=val_c_loader,\n",
    "              val_v_loader=val_v_loader)\n",
    "\n",
    "    this_mc = {'loss': model.val_c_loss,\n",
    "                'val_c_acc': model.val_c_acc,\n",
    "                'val_v_acc': model.val_v_acc,\n",
    "                'mc': mc,\n",
    "                'run_time': time.time()-start_time,\n",
    "                'trajectories': model.trajectories}\n",
    "        \n",
    "    this_mc = json.dumps(this_mc)\n",
    "    \n",
    "    s = 'hw2p2' + '_' + now\n",
    "    # filename = f'../results/{s}.pth' \n",
    "    filename = f'./results/{s}.pth' \n",
    "\n",
    "    torch.save(model.model.state_dict(), filename)\n",
    "\n",
    "    # with open(f'../results/mc_{now}.json', 'w') as bfm: \n",
    "    with open(f'./results/mc_{now}.json', 'w') as bfm: \n",
    "        bfm.write(this_mc)    \n",
    "\n",
    "    if trials is not None: \n",
    "        results = {'loss': model.val_c_loss,\n",
    "                   'val_c_acc': model.val_c_acc,\n",
    "                   'val_v_acc': model.val_v_acc,\n",
    "                   'mc': mc,\n",
    "                   'run_time': time.time()-start_time,\n",
    "                   'trajectories': model.trajectories,\n",
    "                   'status': STATUS_OK}\n",
    "        return results\n",
    "    else: \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from axa_hw2p2.datasets import FaceClassificationDataset, FaceVerificationDataset\n",
    "from axa_hw2p2.losses import CenterLoss\n",
    "from axa_hw2p2.models import _BottleNeck, _MobileNetV2, MobileNetV2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.nn.functional import cosine_similarity, adaptive_avg_pool2d\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {'n_in_ch_bn': hp.choice(label='n_in_ch_bn', options=[3]),\n",
    "         'ls_out_ch_bn': hp.choice(label='ls_out_ch_bn', \n",
    "                                   options=[[16, 24, 32, 64, 96, 160, 320]]),\n",
    "         'ls_n_rep_bn': hp.choice(label='ls_n_rep_bn', \n",
    "                                   options=[[1, 2, 3, 4, 3, 3, 1]]),\n",
    "         'ls_stride_bn': hp.choice(label='ls_stride_bn', \n",
    "                                   options=[[1, 2, 2, 2, 1, 2, 1]]),\n",
    "         'ls_exp_fct_t_bn': hp.choice(label='ls_exp_fct_t_bn', \n",
    "                                      options=[[1, 6, 6, 6, 6, 6, 6]]),\n",
    "         'n_embeddings': hp.choice(label='n_embeddings', options=[1280]),\n",
    "         'n_classes': hp.choice(label='n_classes', options=[6]),\n",
    "         'batch_size': scope.int(hp.choice(label='batch_size', options=[64])),\n",
    "         'lr': hp.loguniform(label='lr', low=np.log(5e-4), high=np.log(0.03)),\n",
    "         'lr_decay': hp.choice(label='lr_decay', options=[0.9,0.92,0.94,\n",
    "                                                          0.96,0.98,1]),\n",
    "         'n_lr_decay_steps': hp.choice(label='n_lr_decay_steps', options=[1,2,4]),\n",
    "         'center_loss': hp.choice(label='center_loss', options=[True,False]),\n",
    "         'lr_cl': hp.choice(label='lr_cl', options=[0.4,0.5,0.6]),\n",
    "         'alpha_cl': hp.choice(label='alpha_cl', options=[0.001,0.01,0.1]),\n",
    "         'n_epochs': hp.choice(label='n_epochs', options=[16]),\n",
    "         'eval_steps': scope.int(hp.choice(label='eval_steps', options=[4])),}\n",
    "\n",
    "print(26*'=')\n",
    "print(np.expand_dims(pd.Series(space).index.to_numpy(), axis = 1))\n",
    "print(26*'=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 8 if torch.cuda.is_available() else 0\n",
    "trials = Trials()\n",
    "fmin_objective = partial(fit_predict, trials=trials, verbose=True)\n",
    "fmin(fmin_objective, space=space, \n",
    "     algo=tpe.suggest, max_evals=20, trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idl_ubuntu",
   "language": "python",
   "name": "idl_ubuntu"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
