{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp hyperoptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/hw2p2'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters optimization\n",
    "\n",
    ">Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# imports\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from torch.nn.functional import cosine_similarity, adaptive_avg_pool2d\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "from hyperopt.pyll.base import scope\n",
    "import json\n",
    "from datetime import datetime\n",
    "import os\n",
    "import time\n",
    "\n",
    "# from datasets import FaceClassificationDataset, FaceVerificationDataset\n",
    "# from losses import CenterLoss\n",
    "# from models.mobilenet import *\n",
    "# from models.resnet import *\n",
    "from hw2p2.datasets import FaceClassificationDataset, FaceVerificationDataset\n",
    "from hw2p2.losses import CenterLoss\n",
    "from hw2p2.models.resnet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def fit_predict(mc, verbose, trials=None):\n",
    "    \n",
    "    assert mc['model'] in ['resnet18', 'resnet34', 'resnet50', 'mobilenet']\n",
    "    \n",
    "    train_loader, clf_loader, vrf_loader = create_dataloaders(mc)\n",
    "\n",
    "    print(f'\\nCurrent directory: {os.getcwd()}\\n')\n",
    "    now = datetime.now().strftime(\"%d-%m-%y_%H-%M-%S\")\n",
    "    print(now)\n",
    "\n",
    "    start_time = time.time()\n",
    "    print('='*26)\n",
    "    print(pd.Series(mc))\n",
    "    print('='*26+'\\n')\n",
    "\n",
    "    if  mc['model'] == 'resnet18': resnet_n_layers = 18\n",
    "    if  mc['model'] == 'resnet34': resnet_n_layers = 34\n",
    "    if  mc['model'] == 'resnet50': resnet_n_layers = 50\n",
    "\n",
    "    model = ResNetN(resnet_n_layers,\n",
    "                    in_channels=mc['in_channels'],\n",
    "                    n_classes=mc['n_classes'],\n",
    "                    lr=mc['lr'],\n",
    "                    lr_decay=mc['lr_decay'],\n",
    "                    n_lr_decay_steps=mc['n_lr_decay_steps'],\n",
    "                    center_loss = mc['center_loss'],\n",
    "                    lr_cl=mc['lr_cl'],\n",
    "                    alpha_cl=mc['alpha_cl'],\n",
    "                    n_epochs=mc['n_epochs'],\n",
    "                    eval_steps=mc['eval_steps'])\n",
    "\n",
    "    model.fit(train_loader=train_loader, \n",
    "              val_c_loader=clf_loader,\n",
    "              val_v_loader=vrf_loader)\n",
    "    \n",
    "    if trials is not None: \n",
    "        results = {'loss': model.train_loss,\n",
    "                   'val_c_loss': model.val_c_loss,\n",
    "                   'train_c_acc': model.train_c_acc,\n",
    "                   'val_c_acc': model.val_c_acc,\n",
    "                   'val_v_acc': model.val_v_acc,\n",
    "                   'mc': mc,\n",
    "                   'run_time': time.time()-start_time,\n",
    "                   'trajectories': model.trajectories,\n",
    "                   'model': model,\n",
    "                   'time_stamp': now,\n",
    "                   'status': STATUS_OK}\n",
    "        return results\n",
    "    else: \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.nn.functional import cosine_similarity, adaptive_avg_pool2d\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================\n",
      "[['model']\n",
      " ['in_channels']\n",
      " ['n_classes']\n",
      " ['batch_size']\n",
      " ['lr']\n",
      " ['lr_decay']\n",
      " ['n_lr_decay_steps']\n",
      " ['center_loss']\n",
      " ['lr_cl']\n",
      " ['alpha_cl']\n",
      " ['n_epochs']\n",
      " ['eval_steps']]\n",
      "==========================\n"
     ]
    }
   ],
   "source": [
    "space = {'model': hp.choice(label='model', options=['resnet18']),\n",
    "        #  'model': hp.choice(label='model', options=['resnet18', 'resnet34', 'resnet50', 'mobilenet']),\n",
    "         'in_channels': hp.choice(label='in_channels', options=[3]),\n",
    "         'n_classes': hp.choice(label='n_classes', options=[50]),\n",
    "         'batch_size': scope.int(hp.choice(label='batch_size', options=[16])),\n",
    "         'lr': hp.loguniform(label='lr', low=np.log(5e-4), high=np.log(0.03)),\n",
    "         'lr_decay': hp.choice(label='lr_decay', options=[0.9,0.92,0.94,\n",
    "                                                          0.96,0.98,1]),\n",
    "         'n_lr_decay_steps': hp.choice(label='n_lr_decay_steps', options=[1,2,4]),\n",
    "         'center_loss': hp.choice(label='center_loss', options=[True,False]),\n",
    "         'lr_cl': hp.choice(label='lr_cl', options=[0.4,0.5,0.6]),\n",
    "         'alpha_cl': hp.choice(label='alpha_cl', options=[0.001,0.01,0.1]),\n",
    "         'n_epochs': hp.choice(label='n_epochs', options=[16]),\n",
    "         'eval_steps': scope.int(hp.choice(label='eval_steps', options=[4])),}\n",
    "\n",
    "print(26*'=')\n",
    "print(np.expand_dims(pd.Series(space).index.to_numpy(), axis = 1))\n",
    "print(26*'=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/hw2p2'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()\n",
    "# os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_idl_ubuntu)",
   "language": "python",
   "name": "conda_idl_ubuntu"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
