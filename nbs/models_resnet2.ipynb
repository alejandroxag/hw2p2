{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BENCHMARK RESNET\n",
    "- https://github.com/kuangliu/pytorch-cifar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
    "                               planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class _ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, input_size=64, num_classes=10):\n",
    "        super(_ResNet, self).__init__()\n",
    "        self.in_planes = input_size\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, input_size, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(input_size)\n",
    "        self.layer1 = self._make_layer(block, input_size, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        \n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(object):\n",
    "    def __init__(self, params):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.params = params\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # Instantiate model\n",
    "        torch.manual_seed(params['random_seed'])\n",
    "        np.random.seed(params['random_seed'])\n",
    "        self.model = _ResNet(block=BasicBlock, \n",
    "                             num_blocks=[2, 2, 2, 2],\n",
    "                             num_classes=params['n_classes'],\n",
    "                             input_size=params['input_size']).to(self.device)\n",
    "\n",
    "    def fit(self, train_loader, val_loader):\n",
    "        \n",
    "        params = self.params\n",
    "        \n",
    "        #------------------------------------- Optimization --------------------------------------#\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer4nn = optim.SGD(self.model.parameters(), lr=params['initial_lr'],\n",
    "                                 momentum=0.9, weight_decay=params['weight_decay'])\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer4nn, step_size=params['adjust_lr_step'], \n",
    "                                              gamma=params['lr_decay'])\n",
    "        \n",
    "        #---------------------------------------- Logging -----------------------------------------#\n",
    "        step = 0\n",
    "        epoch = 0\n",
    "        break_flag = False\n",
    "        self.best_acc = -1\n",
    "        updated_optimizer = False\n",
    "        trajectories = {'step':  [], 'epoch':  [],\n",
    "                        'train_loss': [], 'train_acc': [],\n",
    "                        'val_loss': [], 'val_acc': []}\n",
    "\n",
    "        print('\\n'+'='*43+' Fitting  ResNet '+'='*43)\n",
    "        while step <= params['iterations']:\n",
    "            # Train\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "                step+=1\n",
    "                start = time.time()\n",
    "                \n",
    "                if break_flag: # weird epoch breaker\n",
    "                    continue\n",
    "                \n",
    "                #--------------------------------- Forward and Backward ---------------------------------#\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "\n",
    "                optimizer4nn.zero_grad()\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer4nn.step()\n",
    "\n",
    "                #----------------------------------- Evaluate metrics -----------------------------------#\n",
    "                if (step % params['display_step']) == 0:\n",
    "                    train_loss, train_acc = self.evaluate_performance(loader=train_loader, criterion=criterion)\n",
    "                    val_loss, val_acc = self.evaluate_performance(loader=val_loader, criterion=criterion)\n",
    "                    \n",
    "                    display_str = f'step: {step} time: {time.time()-start:03.3f} ** '\n",
    "                    display_str += f'train_loss: {train_loss:.4f} train_acc {train_acc:.2f} ** '\n",
    "                    display_str += f'val_loss: {val_loss:.4f} val_acc: {val_acc:.2f}'\n",
    "                    print(display_str)\n",
    "                    \n",
    "                    trajectories['train_loss'] += [train_loss]\n",
    "                    trajectories['train_acc']  += [train_acc]\n",
    "                    trajectories['val_loss']   += [val_loss]\n",
    "                    trajectories['val_acc']    += [val_acc]\n",
    "                    \n",
    "                    if val_acc > self.best_acc:\n",
    "                        self.best_acc = val_acc\n",
    "                        \n",
    "                if step > params['iterations']:\n",
    "                    break_flag=True\n",
    "                \n",
    "                # Update optimizer learning rate\n",
    "                scheduler.step()\n",
    "\n",
    "        #---------------------------------------- Final Logs -----------------------------------------#\n",
    "        print('\\n'+'='*43+' Finished Train '+'='*43)\n",
    "        self.train_loss   = trajectories['train_loss'][-1]\n",
    "        self.train_acc    = trajectories['train_acc'][-1]\n",
    "        self.val_loss     = trajectories['val_loss'][-1]\n",
    "        self.val_acc      = trajectories['val_acc'][-1]\n",
    "        self.trajectories = trajectories\n",
    "        \n",
    "    def evaluate_performance(self, loader, criterion):\n",
    "        self.model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, targets) in enumerate(loader):\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        acc = 100.*correct/total\n",
    "        test_loss = test_loss/total\n",
    "            \n",
    "        self.model.train()\n",
    "        return test_loss, acc\n",
    "    \n",
    "    def save_weights(self, path):\n",
    "        torch.save(self.model.state_dict(), path)    \n",
    "\n",
    "    def load_weights(self, path):\n",
    "        self.model.load_state_dict(torch.load(path,\n",
    "                                   map_location=torch.device(self.device)))\n",
    "        self.model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST RESNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=1024, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================================== Fitting  ResNet ===========================================\n",
      "step: 500 time: 11.575 ** train_loss: 0.0122 train_acc 41.95 ** val_loss: 0.0015 val_acc: 42.85\n",
      "step: 1000 time: 11.246 ** train_loss: 0.0091 train_acc 57.98 ** val_loss: 0.0012 val_acc: 57.80\n",
      "\n",
      "=========================================== Finished Train ===========================================\n"
     ]
    }
   ],
   "source": [
    "params = {'input_size': 64,\n",
    "          'n_classes': 10,\n",
    "          #'iterations': 50_000, #(n_samples/batch_size) * epochs\n",
    "          'iterations': 1_000, #(n_samples/batch_size) * epochs\n",
    "          'display_step': 500,\n",
    "          'initial_lr': 0.1,\n",
    "          'lr_decay': 0.5,\n",
    "          'adjust_lr_step': 50_000//2,\n",
    "          'weight_decay': 5e-4,\n",
    "          'random_seed': 1}\n",
    "\n",
    "model = ResNet(params)\n",
    "model.fit(train_loader=trainloader, val_loader=testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_idl_ubuntu)",
   "language": "python",
   "name": "conda_idl_ubuntu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
