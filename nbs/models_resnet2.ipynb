{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models.resnet2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
    "                               planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class _ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, input_size=64, num_classes=10):\n",
    "        super(_ResNet, self).__init__()\n",
    "        self.in_planes = input_size\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, input_size, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(input_size)\n",
    "        self.layer1 = self._make_layer(block, input_size, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        \n",
    "        #self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "        self.linear = nn.Linear(512*4, num_classes)\n",
    "        \n",
    "        print(\"512*block.expansion\", 512*block.expansion)\n",
    "        print(\"num_classes\", num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        embeds = F.avg_pool2d(out, 4)\n",
    "        embeds = embeds.view(embeds.size(0), -1)\n",
    "        last = self.linear(embeds)\n",
    "        return last, embeds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class _CenterLoss(nn.Module):\n",
    "    \"\"\"Center loss.\n",
    "    \n",
    "    Reference:\n",
    "    Wen et al. A Discriminative Feature Learning Approach for Deep Face Recognition. ECCV 2016.\n",
    "    \n",
    "    Args:\n",
    "        num_classes (int): number of classes.\n",
    "        feat_dim (int): feature dimension.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes, feat_dim):\n",
    "        super(_CenterLoss, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.feat_dim = feat_dim\n",
    "        self.centers = nn.Parameter(torch.randn(self.num_classes, self.feat_dim))\n",
    "        self.classes = torch.arange(self.num_classes).long().cuda() # HACK PASADO DE LANZA\n",
    "\n",
    "    def forward(self, x, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: feature matrix with shape (batch_size, feat_dim).\n",
    "            labels: ground truth labels with shape (batch_size).\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        distmat = torch.pow(x, 2).sum(dim=1, \n",
    "                                      keepdim=True).expand(batch_size, \n",
    "                                                           self.num_classes) + \\\n",
    "                  torch.pow(self.centers, 2).sum(dim=1, \n",
    "                                                 keepdim=True).expand(self.num_classes, \n",
    "                                                                      batch_size).t()\n",
    "\n",
    "        distmat = torch.addmm(input=distmat, \n",
    "                              mat1=x, \n",
    "                              mat2=self.centers.t(), \n",
    "                              beta=1, \n",
    "                              alpha=-2)\n",
    "        \n",
    "        labels = labels.unsqueeze(1).expand(batch_size, self.num_classes)\n",
    "        \n",
    "        mask = labels.eq(self.classes.expand(batch_size, self.num_classes))\n",
    "\n",
    "        dist = distmat * mask.float()\n",
    "        loss = dist.clamp(min=1e-12, max=1e+12).sum() / batch_size\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-ec95626c816a>, line 95)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-ec95626c816a>\"\u001b[0;36m, line \u001b[0;32m95\u001b[0m\n\u001b[0;31m    torch.save(state, f'./checkpoint/{selfl.params['experiment_id']}_ckpt.pth')\u001b[0m\n\u001b[0m                                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# export\n",
    "class ResNet(object):\n",
    "    def __init__(self, params):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.params = params\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # Instantiate model\n",
    "        torch.manual_seed(params['random_seed'])\n",
    "        np.random.seed(params['random_seed'])\n",
    "        self.model = _ResNet(block=BasicBlock, \n",
    "                             num_blocks=[2, 2, 2, 2],\n",
    "                             num_classes=params['n_classes'],\n",
    "                             input_size=params['input_size']).to(self.device)\n",
    "        \n",
    "        self.centroids = _CenterLoss(num_classes=params['n_classes'], \n",
    "                                     feat_dim=512*4).to(self.device)\n",
    "\n",
    "    def adjust_lr(self, optimizer, lr_decay):\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = param_group['lr'] * lr_decay\n",
    "\n",
    "    def save_weights(self, path):\n",
    "        torch.save(self.model.state_dict(), path)    \n",
    "\n",
    "    def load_weights(self, path):\n",
    "        self.model.load_state_dict(torch.load(path,\n",
    "                                          map_location=torch.device(self.device)))\n",
    "        self.model.eval()\n",
    "\n",
    "    def fit(self, train_loader, val_loader, vrf_loader):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(self.model.parameters(), lr=self.params['initial_lr'],\n",
    "                              momentum=0.9, weight_decay=self.params['weight_decay'])\n",
    "        coptimizer = optim.SGD(self.centroids.parameters(), lr=self.params['initial_clr'], momentum=0.9)\n",
    "\n",
    "        # Initialize counters and trajectories\n",
    "        step = 0\n",
    "        epoch = 0\n",
    "        self.best_acc = -1\n",
    "        metric_trajectories = {'step':  [],\n",
    "                               'epoch':  [],\n",
    "                               'train_loss': [],\n",
    "                               'train_acc': [],\n",
    "                               'val_loss': [],\n",
    "                               'val_acc': []}\n",
    "\n",
    "        print('\\n'+'='*37+' Fitting  ResNet '+'='*37)\n",
    "        while step <= self.params['iterations']:\n",
    "            # Train\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "                step+=1\n",
    "                if step > self.params['iterations']:\n",
    "                    continue\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                coptimizer.zero_grad()\n",
    "                \n",
    "                outputs, embeds = self.model(inputs)\n",
    "                loss = criterion(outputs, targets) + \\\n",
    "                        self.params['alpha'] * self.centroids(embeds, targets)\n",
    "                loss.backward()\n",
    "                \n",
    "                \n",
    "                # weird lr=1 for weird chain rule\n",
    "                for p in self.centroids.parameters():\n",
    "                    p.grad.data *= (1./self.params['alpha'])\n",
    "                \n",
    "                coptimizer.step()\n",
    "                optimizer.step()\n",
    "\n",
    "                # Evaluate metrics\n",
    "                if (step % self.params['display_step']) == 0:\n",
    "                    train_loss, train_acc = self.evaluate_performance(loader=train_loader, criterion=criterion)\n",
    "                    #train_loss, train_acc = 0, 0\n",
    "                    val_loss, val_acc = self.evaluate_performance(loader=val_loader, criterion=criterion)\n",
    "                    roc, _ = self.evaluate_roc(loader=vrf_loader)\n",
    "                    \n",
    "                    display_str = f'step: {step}\\t train_loss: {train_loss:.4f} train_acc {train_acc:.2f}'\n",
    "                    display_str += f'\\t val_loss: {val_loss:.4f} val_acc: {val_acc:.2f} roc {roc:.2f}'\n",
    "                    print(display_str)\n",
    "                    \n",
    "                    if val_acc > self.best_acc:\n",
    "                        print('Saving..')\n",
    "                        state = {\n",
    "                            'net': self.model.state_dict(),\n",
    "                            'acc': val_acc,\n",
    "                            'epoch': epoch,\n",
    "                        }\n",
    "                        if not os.path.isdir('checkpoint'):\n",
    "                            os.mkdir('checkpoint')\n",
    "                        torch.save(state, f\"./checkpoint/{self.params['experiment_id']}_ckpt.pth\")\n",
    "                        self.best_acc = val_acc\n",
    "                \n",
    "                # Update optimizer learning rate\n",
    "                if step % self.params['adjust_lr_step'] == 0 and step > 0:\n",
    "                    self.adjust_lr(optimizer=optimizer, lr_decay=self.params['lr_decay'])\n",
    "\n",
    "        # Check finish condition\n",
    "        # TODO: check if epoch is interruptable within\n",
    "        # if step==self.iterations: break\n",
    "        print('\\n'+'='*35+' Finished Train '+'='*35)\n",
    "        self.train_loss   = metric_trajectories['train_loss'][-1]\n",
    "        self.train_acc    = metric_trajectories['train_acc'][-1]\n",
    "        self.val_loss     = metric_trajectories['val_loss'][-1]\n",
    "        self.val_acc      = metric_trajectories['val_acc'][-1]\n",
    "        self.trajectories = metric_trajectories\n",
    "        \n",
    "    def evaluate_performance(self, loader, criterion):\n",
    "        self.model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, targets) in enumerate(loader):\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs, _ = self.model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        # Save checkpointorch.\n",
    "        acc = 100.*correct/total\n",
    "        test_loss = test_loss/total\n",
    "            \n",
    "        self.model.train()\n",
    "        return test_loss, acc\n",
    "    \n",
    "    def evaluate_roc(self, loader):\n",
    "        self.model.eval()\n",
    "                \n",
    "        embeds0 = []\n",
    "        embeds1 = []\n",
    "        targets = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (img0, img1, target) in enumerate(loader):\n",
    "                img0 = img0.to(self.device)\n",
    "                img1 = img1.to(self.device)\n",
    "                \n",
    "                embeds0 += [self.model(img0)[1].cpu().numpy()]\n",
    "                embeds1 += [self.model(img1)[1].cpu().numpy()]\n",
    "                targets += [np.expand_dims(target.cpu().numpy(), 1)]\n",
    "                \n",
    "        embeds0  = np.vstack(embeds0)\n",
    "        embeds1  = np.vstack(embeds1)\n",
    "        targets  = np.vstack(targets)\n",
    "\n",
    "        sim_score = np.sum((embeds0 - embeds1) ** 2, axis=1, keepdims=True)        \n",
    "        roc = roc_auc_score(y_true=targets, y_score=sim_score)\n",
    "        \n",
    "        self.model.train()\n",
    "        return roc, sim_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "512*block.expansion 512\n",
      "num_classes 10\n",
      "\n",
      "===================================== Fitting  ResNet =====================================\n",
      "step: 2000\t train_loss: 0.0064 train_acc 71.30\t val_loss: 0.0087 val_acc: 71.10\n",
      "step: 4000\t train_loss: 0.0078 train_acc 68.93\t val_loss: 0.0100 val_acc: 69.41\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-82e719840743>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-7fad53d6c963>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_loader, val_loader)\u001b[0m\n\u001b[1;32m     52\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/idl_ubuntu/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self, set_to_none)\u001b[0m\n\u001b[1;32m    215\u001b[0m                             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "params = {'n_classes': 10,\n",
    "          'iterations': 50_000, #(n_samples/batch_size) * epochs\n",
    "          'display_step': 2_000,\n",
    "          'initial_lr': 0.1,\n",
    "          'lr_decay': 0.5,\n",
    "          'adjust_lr_step': 50_000//2,\n",
    "          'weight_decay': 5e-4,\n",
    "          'random_seed': 1}\n",
    "\n",
    "model = ResNet(params)\n",
    "model.fit(train_loader=trainloader, val_loader=testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_idl_ubuntu)",
   "language": "python",
   "name": "conda_idl_ubuntu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
