{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models.resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    ">Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'axa_hw2p2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-09137fd1f128>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# from losses import CenterLoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0maxa_hw2p2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCenterLoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'axa_hw2p2'"
     ]
    }
   ],
   "source": [
    "#export\n",
    "#imports\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.nn.functional import cosine_similarity, adaptive_avg_pool2d, softmax\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from losses import CenterLoss\n",
    "# from axa_hw2p2.losses import CenterLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class _BottleNeck(nn.Module):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 n_input_ch: int,\n",
    "                 n_output_ch: int,\n",
    "                 stride: int,\n",
    "                 exp_fct_t: int):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        super(_BottleNeck, self).__init__()\n",
    "        self.n_input_ch = n_input_ch\n",
    "        self.n_output_ch = n_output_ch\n",
    "        self.stride = stride\n",
    "\n",
    "        # Expansion block: \n",
    "        # (batch_size, height, width, n_input_ch) -> \n",
    "        # (batch_size, height, width, exp_fct_t*n_input_ch)\n",
    "        # kernel size: 1, stride: 1, padding: 0, groups: 1.\n",
    "        exp_block = []\n",
    "        exp_block.append(nn.Conv2d(in_channels=n_input_ch,\n",
    "                                   out_channels=exp_fct_t*n_input_ch,\n",
    "                                   kernel_size=1,\n",
    "                                   stride=1,\n",
    "                                   padding=0,\n",
    "                                   groups=1,\n",
    "                                   bias=False))\n",
    "        exp_block.append(nn.BatchNorm2d(num_features=exp_fct_t*n_input_ch))\n",
    "        exp_block.append(nn.ReLU6())\n",
    "\n",
    "        # Depthwise convolutional block: \n",
    "        # (batch_size, height, width, exp_fct_t*n_input_ch) -> \n",
    "        # (batch_size, height/stride, width/stride, exp_fct_t*n_input_ch)\n",
    "        # kernel size: 3, stride: stride, \n",
    "        # padding: 1, groups: exp_fct_t*n_input_ch.\n",
    "        dw_conv_block = []\n",
    "        dw_conv_block.append(nn.Conv2d(in_channels=exp_fct_t*n_input_ch,\n",
    "                                       out_channels=exp_fct_t*n_input_ch,\n",
    "                                       kernel_size=3,\n",
    "                                       stride=stride,\n",
    "                                       padding=1,\n",
    "                                       groups=exp_fct_t*n_input_ch, \n",
    "                                       bias=False))\n",
    "        dw_conv_block.append(nn.BatchNorm2d(num_features=exp_fct_t*n_input_ch))\n",
    "        dw_conv_block.append(nn.ReLU6())\n",
    "\n",
    "        # Depthwise convolutional block: \n",
    "        # (batch_size, height, width, exp_fct_t*n_input_ch) -> \n",
    "        # (batch_size, height/stride, width/stride, n_output_ch)\n",
    "        # kernel size: 1, stride: 1, padding: 0, groups: 1.\n",
    "        proj_block = []\n",
    "        proj_block.append(nn.Conv2d(in_channels=exp_fct_t*n_input_ch,\n",
    "                                    out_channels=n_output_ch,\n",
    "                                    kernel_size=1,\n",
    "                                    stride=1,\n",
    "                                    padding=0,\n",
    "                                    groups=1, \n",
    "                                    bias=False))\n",
    "        proj_block.append(nn.BatchNorm2d(num_features=n_output_ch))\n",
    "\n",
    "        self.block = exp_block + dw_conv_block + proj_block\n",
    "        self.block = nn.Sequential(*self.block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        if self.stride == 1 and self.n_input_ch == self.n_output_ch:\n",
    "            return x + self.block(x)\n",
    "        else:\n",
    "            return self.block(x)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class _MobileNetV2(nn.Module):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 n_in_ch_bn: int,\n",
    "                 ls_out_ch_bn: list,\n",
    "                 ls_n_rep_bn: list,\n",
    "                 ls_stride_bn: list,\n",
    "                 ls_exp_fct_t_bn: list,\n",
    "                 n_embeddings: int,\n",
    "                 n_classes: int):\n",
    "        \n",
    "        super(_MobileNetV2, self).__init__()\n",
    "\n",
    "        assert len(ls_out_ch_bn) == len(ls_n_rep_bn)\n",
    "        assert len(ls_n_rep_bn) == len(ls_stride_bn)\n",
    "        assert len(ls_stride_bn) == len(ls_exp_fct_t_bn)\n",
    "\n",
    "        # Initial fully convolution block\n",
    "        # (batch_size, 64, 64, 3) ->\n",
    "        # (batch_size, 64, 64, n_in_ch_bn)\n",
    "        # kernel size: 1, stride: 1, padding: 0, groups: 1.\n",
    "        # (stride is 1 instead of two because images are small (64x64))\n",
    "        block1 = []\n",
    "        block1.append(nn.Conv2d(in_channels=3,\n",
    "                                out_channels=n_in_ch_bn,\n",
    "                                kernel_size=3,\n",
    "                                stride=1,\n",
    "                                padding=0,\n",
    "                                groups=1,\n",
    "                                bias=False))\n",
    "        block1.append(nn.BatchNorm2d(n_in_ch_bn))\n",
    "        block1.append(nn.ReLU6())\n",
    "\n",
    "        # Bottlenecks\n",
    "        bottlenecks = []\n",
    "        n_input_ch = n_in_ch_bn\n",
    "\n",
    "        for i in range(len(ls_out_ch_bn)):\n",
    "            \n",
    "            c = ls_out_ch_bn[i]\n",
    "            n = ls_n_rep_bn[i]\n",
    "            s = ls_stride_bn[i]\n",
    "            t = ls_exp_fct_t_bn[i]\n",
    "\n",
    "            for j in range(n):\n",
    "                \n",
    "                if j == 0: stride = 1\n",
    "                else: stride = s\n",
    "                bottlenecks.append(_BottleNeck(n_input_ch=n_input_ch,\n",
    "                                               n_output_ch=c,\n",
    "                                               stride=stride,\n",
    "                                               exp_fct_t=t))\n",
    "                n_input_ch = c\n",
    "        \n",
    "        # Last 1x1 convolution block\n",
    "        blockn = []\n",
    "        blockn.append(nn.Conv2d(in_channels=n_input_ch,\n",
    "                                out_channels=n_embeddings,\n",
    "                                kernel_size=1,\n",
    "                                stride=1,\n",
    "                                padding=0,\n",
    "                                groups=1,\n",
    "                                bias=False))\n",
    "        blockn.append(nn.BatchNorm2d(n_embeddings))\n",
    "        blockn.append(nn.ReLU6())\n",
    "\n",
    "        self.net = block1 + bottlenecks + blockn\n",
    "        self.net = nn.Sequential(*self.net)\n",
    "        self.classifier = nn.Linear(in_features=n_embeddings, \n",
    "                                    out_features=n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        x = self.net(x)\n",
    "        x = adaptive_avg_pool2d(x, 1).reshape(x.shape[0], -1)\n",
    "        embeddings = x\n",
    "        cl_output = self.classifier(x)\n",
    "        \n",
    "        return embeddings, cl_output\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (2): ReLU6()\n  (3): _BottleNeck(\n    (block): Sequential(\n      (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU6()\n      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU6()\n      (6): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (4): _BottleNeck(\n    (block): Sequential(\n      (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU6()\n      (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n      (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU6()\n      (6): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (5): _BottleNeck(\n    (block): Sequential(\n      (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU6()\n      (3): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n      (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU6()\n      (6): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (6): _BottleNeck(\n    (block): Sequential(\n      (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU6()\n      (3): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n      (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU6()\n      (6): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (7): _BottleNeck(\n    (block): Sequential(\n      (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU6()\n      (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n      (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU6()\n      (6): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (8): _BottleNeck(\n    (block): Sequential(\n      (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU6()\n      (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n      (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU6()\n      (6): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (9): _BottleNeck(\n    (block): Sequential(\n      (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU6()\n      (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n      (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU6()\n      (6): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (10): _BottleNeck(\n    (block): Sequential(\n      (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU6()\n      (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n      (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU6()\n      (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (11): _BottleNeck(\n    (block): Sequential(\n      (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU6()\n      (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n      (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU6()\n      (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (12): _BottleNeck(\n    (block): Sequential(\n      (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU6()\n      (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n      (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU6()\n      (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (13): _BottleNeck(\n    (block): Sequential(\n      (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU6()\n      (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n      (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU6()\n      (6): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (14): _BottleNeck(\n    (block): Sequential(\n      (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU6()\n      (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n      (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU6()\n      (6): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (15): _BottleNeck(\n    (block): Sequential(\n      (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU6()\n      (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n      (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU6()\n      (6): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (16): _BottleNeck(\n    (block): Sequential(\n      (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU6()\n      (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n      (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU6()\n      (6): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (17): _BottleNeck(\n    (block): Sequential(\n      (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU6()\n      (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=960, bias=False)\n      (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU6()\n      (6): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (18): _BottleNeck(\n    (block): Sequential(\n      (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU6()\n      (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=960, bias=False)\n      (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU6()\n      (6): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (19): _BottleNeck(\n    (block): Sequential(\n      (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU6()\n      (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n      (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU6()\n      (6): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (7): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (20): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (21): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (22): ReLU6()\n)\n"
     ]
    }
   ],
   "source": [
    "# Standard MobileNetV2 architecture\n",
    "\n",
    "n_in_ch_bn = 32\n",
    "ls_out_ch_bn = [16, 24, 32, 64, 96, 160, 320]\n",
    "ls_n_rep_bn = [1, 2, 3, 4, 3, 3, 1]\n",
    "ls_stride_bn = [1, 2, 2, 2, 1, 2, 1]\n",
    "ls_exp_fct_t_bn = [1, 6, 6, 6, 6, 6, 6]\n",
    "n_embeddings = 1280\n",
    "n_classes = 4000\n",
    "\n",
    "model1 = _MobileNetV2(n_in_ch_bn=n_in_ch_bn,\n",
    "                      ls_out_ch_bn=ls_out_ch_bn,\n",
    "                      ls_n_rep_bn=ls_n_rep_bn,\n",
    "                      ls_stride_bn=ls_stride_bn,\n",
    "                      ls_exp_fct_t_bn=ls_exp_fct_t_bn,\n",
    "                      n_embeddings=n_embeddings,\n",
    "                      n_classes=n_classes)\n",
    "\n",
    "print(model1.net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MobileNetV2():\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 n_in_ch_bn: int,\n",
    "                 ls_out_ch_bn: list,\n",
    "                 ls_n_rep_bn: list,\n",
    "                 ls_stride_bn: list,\n",
    "                 ls_exp_fct_t_bn: list,\n",
    "                 n_embeddings: int,\n",
    "                 n_classes: int,\n",
    "                 lr: float,\n",
    "                 lr_decay: float,\n",
    "                 n_lr_decay_steps: int,\n",
    "                 center_loss: bool,\n",
    "                 lr_cl: float,\n",
    "                 alpha_cl: float,\n",
    "                 n_epochs: int,\n",
    "                 eval_steps: int):\n",
    "\n",
    "        # Architecture parameters\n",
    "        self.n_in_ch_bn = n_in_ch_bn\n",
    "        self.ls_out_ch_bn = ls_out_ch_bn\n",
    "        self.ls_n_rep_bn = ls_n_rep_bn\n",
    "        self.ls_stride_bn = ls_stride_bn\n",
    "        self.ls_exp_fct_t_bn = ls_exp_fct_t_bn\n",
    "        self.n_embeddings = n_embeddings\n",
    "        self.n_classes = n_classes\n",
    "        self.center_loss = center_loss\n",
    "\n",
    "        # Optimization parameters\n",
    "        self.lr = lr\n",
    "        self.lr_decay = lr_decay\n",
    "        self.n_lr_decay_steps = n_lr_decay_steps\n",
    "        self.lr_cl = lr_cl\n",
    "        self.alpha_cl = alpha_cl\n",
    "        self.n_epochs = n_epochs\n",
    "        self.eval_steps = eval_steps\n",
    "\n",
    "        self.model = _MobileNetV2(n_in_ch_bn=n_in_ch_bn,\n",
    "                                  ls_out_ch_bn=ls_out_ch_bn,\n",
    "                                  ls_n_rep_bn=ls_n_rep_bn,\n",
    "                                  ls_stride_bn=ls_stride_bn,\n",
    "                                  ls_exp_fct_t_bn=ls_exp_fct_t_bn,\n",
    "                                  n_embeddings=n_embeddings,\n",
    "                                  n_classes=n_classes)\n",
    "\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    def fit(self, train_loader, val_c_loader, val_v_loader):\n",
    "\n",
    "        print(\"=\"*30 + 'Start Fitting' + \"=\"*30)\n",
    "        self.model.to(self.device)\n",
    "        self.model.train()\n",
    "        \n",
    "        cross_entroypy_loss_f = nn.CrossEntropyLoss()\n",
    "        center_loss_f = CenterLoss(num_classes=self.n_classes,\n",
    "                                   feat_dim=self.n_embeddings,\n",
    "                                   use_gpu=torch.cuda.is_available())\n",
    "    \n",
    "        # optimizer = Adam(self.model.parameters(), \n",
    "        #                  lr=self.lr, \n",
    "        #                  weight_decay=0.00004)\n",
    "\n",
    "        # optimizer_centerloss = Adam(center_loss_f.parameters(),\n",
    "        #                             lr=self.lr_cl)\n",
    "\n",
    "        optimizer = SGD(self.model.parameters(), \n",
    "                        lr=self.lr, \n",
    "                        weight_decay=0.00004,\n",
    "                        momentum=0.9)\n",
    "\n",
    "        optimizer_centerloss = SGD(center_loss_f.parameters(),\n",
    "                                   lr=self.lr_cl)                            \n",
    "\n",
    "        scheduler = StepLR(optimizer=optimizer, \n",
    "                           step_size=self.n_epochs//self.n_lr_decay_steps,\n",
    "                           gamma=self.lr_decay)\n",
    "        \n",
    "        self.train_loss = -1\n",
    "        self.val_c_loss = -1\n",
    "        self.val_c_acc = 0\n",
    "        self.val_v_acc = 0\n",
    "        self.trajectories = {'epoch': [],\n",
    "                             'train_loss': [],\n",
    "                             'val_c_loss': [],\n",
    "                             'val_c_acc': [],\n",
    "                             'val_v_acc':[]}\n",
    "\n",
    "        for epoch in range(self.n_epochs):\n",
    "            \n",
    "            train_loss = 0\n",
    "\n",
    "            for batch_idx, (img, label) in enumerate(train_loader):\n",
    "                # print(f'Train. epoch: {epoch}, batch_idx: {batch_idx}')\n",
    "                img = img.to(self.device)\n",
    "                label = label.to(self.device)\n",
    "                \n",
    "                embeddings, cl_output = self.model(img)\n",
    "\n",
    "                if self.center_loss == True:\n",
    "                    loss = self.alpha_cl * center_loss_f(embeddings, label) + \\\n",
    "                       cross_entroypy_loss_f(cl_output, label)\n",
    "\n",
    "                else:\n",
    "                    loss = cross_entroypy_loss_f(cl_output, label)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                if self.center_loss == True: \n",
    "                    optimizer_centerloss.zero_grad()\n",
    "\n",
    "                loss.backward()\n",
    "                \n",
    "                if self.center_loss == True:\n",
    "                    for p in center_loss_f.parameters():\n",
    "                        p.grad.data *= (1./self.alpha_cl)\n",
    "                \n",
    "                optimizer.step()\n",
    "\n",
    "                if self.center_loss == True:\n",
    "                    optimizer_centerloss.step()\n",
    "\n",
    "                scheduler.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "            \n",
    "            train_loss /= len(train_loader)         \n",
    "\n",
    "            if epoch % self.eval_steps == 0:\n",
    "                val_c_loss, val_c_acc, val_v_acc = \\\n",
    "                    self.evaluate_performance(val_c_loader, \n",
    "                                              val_v_loader)\n",
    "        \n",
    "                self.trajectories['epoch'].append(epoch)\n",
    "                self.trajectories['train_loss'].append(train_loss)\n",
    "                self.trajectories['val_c_loss'].append(val_c_loss)\n",
    "                self.trajectories['val_c_acc'].append(val_c_acc)\n",
    "                self.trajectories['val_v_acc'].append(val_v_acc)\n",
    "\n",
    "                display_str = f'epoch: {epoch} '\n",
    "                display_str += f'train_loss: {np.round(train_loss,4)} '\n",
    "                display_str += f'val_c_loss: {np.round(val_c_loss,4)} '\n",
    "                display_str += f'val_c_acc: {np.round(val_c_acc,4):.2%} '\n",
    "                display_str += f'val_v_acc: {np.round(val_v_acc,4):.2%} '\n",
    "                print(display_str)\n",
    "\n",
    "                if self.val_c_loss > val_c_loss: self.val_c_loss = val_c_loss\n",
    "                if self.train_loss > train_loss: self.train_loss = train_loss\n",
    "                if self.val_c_acc < val_c_acc: self.val_c_acc = val_c_acc\n",
    "                if self.val_v_acc < val_v_acc: self.val_v_acc = val_v_acc\n",
    "        \n",
    "        print(\"=\"*72+\"\\n\")\n",
    "\n",
    "\n",
    "    def evaluate_performance(self, val_c_loader, val_v_loader):\n",
    "\n",
    "        cross_entroypy_loss_f = nn.CrossEntropyLoss()\n",
    "        center_loss_f = CenterLoss(num_classes=self.n_classes,\n",
    "                                   feat_dim=self.n_embeddings,\n",
    "                                   use_gpu=torch.cuda.is_available())\n",
    "        \n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "        val_c_loss = 0.0\n",
    "        total_predictions = 0.0\n",
    "        correct_predictions = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (img, label) in enumerate(val_c_loader):\n",
    "                # print(f'Val class. batch_idx: {batch_idx}')\n",
    "                img = img.to(self.device)\n",
    "                label = label.to(self.device)\n",
    "\n",
    "                embeddings, cl_output = self.model(img)\n",
    "\n",
    "                if self.center_loss == True:\n",
    "                    loss = self.alpha_cl * center_loss_f(embeddings, label) + \\\n",
    "                       cross_entroypy_loss_f(cl_output, label)\n",
    "\n",
    "                else:\n",
    "                    loss = cross_entroypy_loss_f(cl_output, label)\n",
    "\n",
    "                loss = loss.detach()\n",
    "                val_c_loss += loss.item()\n",
    "\n",
    "                # predicted = torch.argmax(cl_output.data, 1)\n",
    "                _, predicted = torch.max(softmax(cl_output, dim=1), 1)\n",
    "                predicted = predicted.view(-1)\n",
    "                total_predictions += len(label)\n",
    "                # correct_predictions += (predicted == label).sum().item()\n",
    "                correct_predictions += torch.sum(torch.eq(predicted, label)).item()\n",
    "\n",
    "        val_c_loss /= len(val_c_loader) \n",
    "        val_c_acc = correct_predictions/total_predictions\n",
    "\n",
    "        similarity = np.array([])\n",
    "        ver_bool = np.array([])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (img_0, img_1, target) in enumerate(val_v_loader):\n",
    "                # print(f'Val ver. batch_idx: {batch_idx}')\n",
    "                img_0 = img_0.to(self.device)\n",
    "                img_1 = img_1.to(self.device)\n",
    "\n",
    "                emb_0 = self.model(img_0)[0]\n",
    "                emb_1 = self.model(img_1)[0]\n",
    "\n",
    "                sim_score = cosine_similarity(emb_0, emb_1)\n",
    "                similarity = np.append(similarity, sim_score.cpu().numpy().reshape(-1))\n",
    "                ver_bool = np.append(ver_bool, target)\n",
    "            \n",
    "        val_v_acc = roc_auc_score(ver_bool, similarity)\n",
    "\n",
    "        return val_c_loss, val_c_acc, val_v_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'axa_hw2p2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b412147ffd62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0maxa_hw2p2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFaceClassificationDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFaceVerificationDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'axa_hw2p2'"
     ]
    }
   ],
   "source": [
    "from axa_hw2p2.datasets import FaceClassificationDataset, FaceVerificationDataset\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "sample_train = np.array(range(6))\n",
    "sample_val_c = list(range(2))\n",
    "sample_val_c = np.array([sample_train[i] for i in sample_val_c])\n",
    "sample_val_v = np.array(range(2))\n",
    "\n",
    "train_dataset = FaceClassificationDataset(sample_train, mode='train')\n",
    "val_c_dataset = FaceClassificationDataset(sample_val_c, mode='val')\n",
    "val_v_dataset = FaceVerificationDataset(sample_val_v, mode='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Architecture parameters\n",
    "mc = {}\n",
    "mc['n_in_ch_bn'] = 3\n",
    "mc['ls_out_ch_bn'] = [16, 24, 32, 64, 96, 160, 320]\n",
    "mc['ls_n_rep_bn'] = [1, 2, 3, 4, 3, 3, 1]\n",
    "mc['ls_stride_bn'] = [1, 2, 2, 2, 1, 2, 1]\n",
    "mc['ls_exp_fct_t_bn'] = [1, 6, 6, 6, 6, 6, 6]\n",
    "mc['n_embeddings'] = 1280\n",
    "mc['n_classes'] = len(np.unique(train_dataset.labels))\n",
    "\n",
    "# Optimization and regularization parameters\n",
    "mc['batch_size'] = 64\n",
    "mc['lr'] = 0.001\n",
    "mc['lr_decay'] = 0.99\n",
    "mc['n_lr_decay_steps'] = 4\n",
    "mc['lr_cl'] = 0.5\n",
    "mc['alpha_cl'] = 0.01\n",
    "mc['n_epochs'] = 16\n",
    "mc['eval_steps'] = 4\n",
    "\n",
    "print(77*'=')\n",
    "print(pd.Series(mc))\n",
    "print(77*'=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MobileNetV2(n_in_ch_bn=mc['n_in_ch_bn'],\n",
    "                    ls_out_ch_bn=mc['ls_out_ch_bn'],\n",
    "                    ls_n_rep_bn=mc['ls_n_rep_bn'],\n",
    "                    ls_stride_bn=mc['ls_stride_bn'],\n",
    "                    ls_exp_fct_t_bn=mc['ls_exp_fct_t_bn'],\n",
    "                    n_embeddings=mc['n_embeddings'],\n",
    "                    n_classes=mc['n_classes'],\n",
    "                    lr=mc['lr'],\n",
    "                    lr_decay=mc['lr_decay'],\n",
    "                    n_lr_decay_steps=mc['n_lr_decay_steps'],\n",
    "                    lr_cl=mc['lr_cl'],\n",
    "                    alpha_cl=mc['alpha_cl'],\n",
    "                    n_epochs=mc['n_epochs'],\n",
    "                    eval_steps=mc['eval_steps'])\n",
    "print(model.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, \n",
    "                          shuffle=True, \n",
    "                          batch_size=mc['batch_size'], \n",
    "                          drop_last=True)\n",
    "\n",
    "val_c_loader = DataLoader(val_c_dataset, \n",
    "                          shuffle=False, \n",
    "                          batch_size=1, \n",
    "                          drop_last=True)\n",
    "                          \n",
    "val_v_loader = DataLoader(val_v_dataset, \n",
    "                          shuffle=False, \n",
    "                          batch_size=1, \n",
    "                          drop_last=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_loader=train_loader,\n",
    "          val_c_loader=val_c_loader,\n",
    "          val_v_loader=val_v_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('idl_ubuntu': conda)",
   "metadata": {
    "interpreter": {
     "hash": "90fe67124204a04bb5d130edc44abf452890e25295d02a40ff695cfcd1c7864c"
    }
   },
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
