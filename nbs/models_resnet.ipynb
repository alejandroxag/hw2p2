{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models.resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    ">Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#imports\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.nn.functional import cosine_similarity, adaptive_avg_pool2d, softmax\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from functools import partial\n",
    "# from losses import CenterLoss\n",
    "from axa_hw2p2.losses import CenterLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Conv2dAuto(nn.Conv2d):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.padding =  (self.kernel_size[0] // 2, \n",
    "                         self.kernel_size[1] // 2) # dynamic add padding based on the kernel_size\n",
    "        \n",
    "conv3x3 = partial(Conv2dAuto, kernel_size=3, bias=False)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2dAuto(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "conv3x3 = partial(Conv2dAuto, kernel_size=3, bias=False)\n",
    "conv = conv3x3(in_channels=32, out_channels=64)\n",
    "print(conv)\n",
    "del conv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, \n",
    "                 in_channels: int,\n",
    "                 out_channels: int):\n",
    "        super().__init__()\n",
    "        self.in_channels, self.out_channels =  in_channels, out_channels\n",
    "        self.blocks = nn.Identity()\n",
    "        self.activation_f = nn.ReLU(inplace=True)\n",
    "        self.shortcut = nn.Identity()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        if self.should_apply_shortcut: residual = self.shortcut(x)\n",
    "        x = self.blocks(x)\n",
    "        x += residual\n",
    "        return x\n",
    "    \n",
    "    @property\n",
    "    def should_apply_shortcut(self):\n",
    "        return self.in_channels != self.out_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResidualBlock(\n",
       "  (blocks): Identity()\n",
       "  (activation_f): ReLU(inplace=True)\n",
       "  (shortcut): Identity()\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ResidualBlock(32, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ResNetResidualBlock(ResidualBlock):\n",
    "    def __init__(self, \n",
    "                 in_channels: int, \n",
    "                 out_channels: int, \n",
    "                 expansion=1, \n",
    "                 downsampling=1, \n",
    "                 conv=conv3x3, \n",
    "                 *args, \n",
    "                 **kwargs):\n",
    "        super().__init__(in_channels=in_channels, \n",
    "                         out_channels=out_channels, \n",
    "                         *args, \n",
    "                         **kwargs)\n",
    "        self.expansion = expansion\n",
    "        self.downsampling = downsampling\n",
    "        self.conv = conv\n",
    "\n",
    "        if self.should_apply_shortcut:\n",
    "            self.shortcut = nn.Sequential(nn.Conv2d(self.in_channels, \n",
    "                                                    self.expanded_channels, \n",
    "                                                    kernel_size=1,\n",
    "                                                    stride=self.downsampling, \n",
    "                                                    bias=False),\n",
    "                                          nn.BatchNorm2d(self.expanded_channels)) \n",
    "        else: None        \n",
    "        \n",
    "    @property\n",
    "    def expanded_channels(self):\n",
    "        return self.out_channels * self.expansion\n",
    "    \n",
    "    @property\n",
    "    def should_apply_shortcut(self):\n",
    "        return self.in_channels != self.expanded_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetResidualBlock(\n",
       "  (blocks): Identity()\n",
       "  (activation_f): ReLU(inplace=True)\n",
       "  (shortcut): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ResNetResidualBlock(32, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def conv_bn(in_channels:int, \n",
    "            out_channels: int, \n",
    "            conv, \n",
    "            *args, \n",
    "            **kwargs):\n",
    "\n",
    "    return nn.Sequential(conv(in_channels, out_channels, *args, **kwargs), nn.BatchNorm2d(out_channels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ResNetBasicBlock(ResNetResidualBlock):\n",
    "    \"\"\"\n",
    "    Basic ResNet block composed by two layers of 3x3conv/batchnorm/activation\n",
    "    \"\"\"\n",
    "    expansion = 1\n",
    "    def __init__(self, \n",
    "                 in_channels: int, \n",
    "                 out_channels: int, \n",
    "                 *args, \n",
    "                 **kwargs):\n",
    "        super().__init__(in_channels=in_channels, \n",
    "                         out_channels=out_channels, \n",
    "                         *args, \n",
    "                         **kwargs)\n",
    "\n",
    "        self.blocks = nn.Sequential(\n",
    "            conv_bn(in_channels=self.in_channels, \n",
    "                    out_channels=self.out_channels, \n",
    "                    conv=self.conv, \n",
    "                    bias=False, \n",
    "                    stride=self.downsampling),\n",
    "            self.activation_f,\n",
    "            conv_bn(in_channels=self.out_channels, \n",
    "                    out_channels=self.expanded_channels, \n",
    "                    conv=self.conv, \n",
    "                    bias=False),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNetBasicBlock(\n  (blocks): Sequential(\n    (0): Sequential(\n      (0): Conv2dAuto(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): ReLU(inplace=True)\n    (2): Sequential(\n      (0): Conv2dAuto(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (activation_f): ReLU(inplace=True)\n  (shortcut): Sequential(\n    (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n)\n"
     ]
    }
   ],
   "source": [
    "dummy = torch.ones((1, 32, 224, 224))\n",
    "\n",
    "block = ResNetBasicBlock(32, 64)\n",
    "block(dummy).shape\n",
    "print(block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ResNetBottleNeckBlock(ResNetResidualBlock):\n",
    "    expansion = 4\n",
    "    def __init__(self, \n",
    "                 in_channels: int, \n",
    "                 out_channels: int, \n",
    "                 *args, \n",
    "                 **kwargs):\n",
    "        super().__init__(in_channels=in_channels, \n",
    "                         out_channels=out_channels, \n",
    "                         expansion=4, \n",
    "                         *args, \n",
    "                         **kwargs)\n",
    "        self.blocks = nn.Sequential(\n",
    "           conv_bn(in_channels=self.in_channels, \n",
    "                   out_channels=self.out_channels, \n",
    "                   conv=self.conv,\n",
    "                   kernel_size=1),\n",
    "           self.activation_f,\n",
    "           conv_bn(in_channels=self.out_channels, \n",
    "                   out_channels=self.out_channels, \n",
    "                   conv=self.conv, \n",
    "                   kernel_size=3, \n",
    "                   stride=self.downsampling),\n",
    "           self.activation_f,\n",
    "           conv_bn(in_channels=self.out_channels, \n",
    "                   out_channels=self.expanded_channels, \n",
    "                   conv=self.conv, \n",
    "                   kernel_size=1),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNetBottleNeckBlock(\n  (blocks): Sequential(\n    (0): Sequential(\n      (0): Conv2dAuto(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): ReLU(inplace=True)\n    (2): Sequential(\n      (0): Conv2dAuto(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (3): ReLU(inplace=True)\n    (4): Sequential(\n      (0): Conv2dAuto(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (activation_f): ReLU(inplace=True)\n  (shortcut): Sequential(\n    (0): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n)\n"
     ]
    }
   ],
   "source": [
    "dummy = torch.ones((1, 32, 10, 10))\n",
    "\n",
    "block = ResNetBottleNeckBlock(32, 64)\n",
    "block(dummy).shape\n",
    "print(block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ResNetLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    A ResNet layer composed by `n` blocks stacked one after the other\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 in_channels: int, \n",
    "                 out_channels: int, \n",
    "                 block=ResNetBasicBlock, \n",
    "                 n_blocks=1, \n",
    "                 *args, \n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "        # 'We perform downsampling directly by convolutional layers that have a stride of 2.'\n",
    "        if in_channels != out_channels: downsampling = 2\n",
    "        else: downsampling = 1\n",
    "        \n",
    "        self.blocks = nn.Sequential(\n",
    "            block(in_channels=in_channels , \n",
    "                  out_channels=out_channels, \n",
    "                  *args, \n",
    "                  **kwargs, \n",
    "                  downsampling=downsampling),\n",
    "            *[block(in_channels=out_channels * block.expansion, \n",
    "                    out_channels=out_channels, \n",
    "                    downsampling=1, \n",
    "                    *args, \n",
    "                    **kwargs) for _ in range(n_blocks - 1)]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.blocks(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 24, 24])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = torch.ones((1, 64, 48, 48))\n",
    "\n",
    "layer = ResNetLayer(64, 128, block=ResNetBasicBlock, n_blocks=3)\n",
    "layer(dummy).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ResNetEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    ResNet encoder composed by layers with increasing features.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 in_channels=3, \n",
    "                 blocks_sizes=[64, 128, 256, 512], \n",
    "                 deepths=[2,2,2,2], \n",
    "                 block=ResNetBasicBlock, \n",
    "                 *args, \n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.blocks_sizes = blocks_sizes\n",
    "        \n",
    "        self.gate = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, \n",
    "                      out_channels=self.blocks_sizes[0], \n",
    "                      kernel_size=7, \n",
    "                      stride=2, \n",
    "                      padding=3, \n",
    "                      bias=False),\n",
    "            nn.BatchNorm2d(self.blocks_sizes[0]),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, \n",
    "                         stride=2, \n",
    "                         padding=1)\n",
    "        )\n",
    "        \n",
    "        self.in_out_block_sizes = list(zip(blocks_sizes, blocks_sizes[1:]))\n",
    "\n",
    "        self.blocks = nn.ModuleList([ \n",
    "            ResNetLayer(in_channels=blocks_sizes[0], \n",
    "                        out_channels=blocks_sizes[0], \n",
    "                        n_blocks=deepths[0], \n",
    "                        block=block,\n",
    "                        *args, \n",
    "                        **kwargs),\n",
    "            *[ResNetLayer(in_channels=in_channels * block.expansion, \n",
    "                          out_channels=out_channels, \n",
    "                          n_blocks=n, \n",
    "                          block=block, \n",
    "                          *args, \n",
    "                          **kwargs) \n",
    "              for (in_channels, out_channels), n in zip(self.in_out_block_sizes, deepths[1:])]       \n",
    "        ])\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.gate(x)\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ResnetDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    This class represents the tail of ResNet. It performs a global pooling and maps the output to the\n",
    "    correct class by using a fully connected layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 in_features: int, \n",
    "                 n_classes: int):\n",
    "        super().__init__()\n",
    "        self.avg = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.decoder = nn.Linear(in_features=in_features, \n",
    "                                 out_features=n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.avg(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class _ResNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 in_channels: int, \n",
    "                 n_classes: int, \n",
    "                 *args, \n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "        self.encoder = ResNetEncoder(in_channels=in_channels, \n",
    "                                     *args, \n",
    "                                     **kwargs)\n",
    "\n",
    "        n_features = self.encoder.blocks[-1].blocks[-1].expanded_channels\n",
    "        self.decoder = ResnetDecoder(in_features=n_features,\n",
    "                                     n_classes=n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def resnet18(in_channels: int, \n",
    "             n_classes: int, \n",
    "             block=ResNetBasicBlock, \n",
    "             *args, \n",
    "             **kwargs):\n",
    "\n",
    "    return _ResNet(in_channels=in_channels, \n",
    "                   n_classes=n_classes, \n",
    "                   block=block, \n",
    "                   deepths=[2, 2, 2, 2], \n",
    "                   *args, \n",
    "                   **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def resnet34(in_channels: int, \n",
    "             n_classes: int, \n",
    "             block=ResNetBasicBlock, \n",
    "             *args, \n",
    "             **kwargs):\n",
    "\n",
    "    return _ResNet(in_channels=in_channels, \n",
    "                   n_classes=n_classes, \n",
    "                   block=block, \n",
    "                   deepths=[3, 4, 6, 3], \n",
    "                   *args, \n",
    "                   **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def resnet50(in_channels: int, \n",
    "             n_classes: int, \n",
    "             block=ResNetBottleNeckBlock, \n",
    "             *args, \n",
    "             **kwargs):\n",
    "\n",
    "    return _ResNet(in_channels=in_channels, \n",
    "                   n_classes=n_classes, \n",
    "                   block=block, \n",
    "                   deepths=[3, 4, 6, 3], \n",
    "                   *args, \n",
    "                   **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1         [-1, 64, 112, 112]           9,408\n       BatchNorm2d-2         [-1, 64, 112, 112]             128\n              ReLU-3         [-1, 64, 112, 112]               0\n         MaxPool2d-4           [-1, 64, 56, 56]               0\n            Conv2d-5          [-1, 256, 56, 56]          16,384\n       BatchNorm2d-6          [-1, 256, 56, 56]             512\n        Conv2dAuto-7           [-1, 64, 56, 56]           4,096\n       BatchNorm2d-8           [-1, 64, 56, 56]             128\n              ReLU-9           [-1, 64, 56, 56]               0\n             ReLU-10           [-1, 64, 56, 56]               0\n       Conv2dAuto-11           [-1, 64, 56, 56]          36,864\n      BatchNorm2d-12           [-1, 64, 56, 56]             128\n             ReLU-13           [-1, 64, 56, 56]               0\n             ReLU-14           [-1, 64, 56, 56]               0\n       Conv2dAuto-15          [-1, 256, 56, 56]          16,384\n      BatchNorm2d-16          [-1, 256, 56, 56]             512\nResNetBottleNeckBlock-17          [-1, 256, 56, 56]               0\n       Conv2dAuto-18           [-1, 64, 56, 56]          16,384\n      BatchNorm2d-19           [-1, 64, 56, 56]             128\n             ReLU-20           [-1, 64, 56, 56]               0\n             ReLU-21           [-1, 64, 56, 56]               0\n       Conv2dAuto-22           [-1, 64, 56, 56]          36,864\n      BatchNorm2d-23           [-1, 64, 56, 56]             128\n             ReLU-24           [-1, 64, 56, 56]               0\n             ReLU-25           [-1, 64, 56, 56]               0\n       Conv2dAuto-26          [-1, 256, 56, 56]          16,384\n      BatchNorm2d-27          [-1, 256, 56, 56]             512\nResNetBottleNeckBlock-28          [-1, 256, 56, 56]               0\n       Conv2dAuto-29           [-1, 64, 56, 56]          16,384\n      BatchNorm2d-30           [-1, 64, 56, 56]             128\n             ReLU-31           [-1, 64, 56, 56]               0\n             ReLU-32           [-1, 64, 56, 56]               0\n       Conv2dAuto-33           [-1, 64, 56, 56]          36,864\n      BatchNorm2d-34           [-1, 64, 56, 56]             128\n             ReLU-35           [-1, 64, 56, 56]               0\n             ReLU-36           [-1, 64, 56, 56]               0\n       Conv2dAuto-37          [-1, 256, 56, 56]          16,384\n      BatchNorm2d-38          [-1, 256, 56, 56]             512\nResNetBottleNeckBlock-39          [-1, 256, 56, 56]               0\n      ResNetLayer-40          [-1, 256, 56, 56]               0\n           Conv2d-41          [-1, 512, 28, 28]         131,072\n      BatchNorm2d-42          [-1, 512, 28, 28]           1,024\n       Conv2dAuto-43          [-1, 128, 56, 56]          32,768\n      BatchNorm2d-44          [-1, 128, 56, 56]             256\n             ReLU-45          [-1, 128, 56, 56]               0\n             ReLU-46          [-1, 128, 56, 56]               0\n       Conv2dAuto-47          [-1, 128, 28, 28]         147,456\n      BatchNorm2d-48          [-1, 128, 28, 28]             256\n             ReLU-49          [-1, 128, 28, 28]               0\n             ReLU-50          [-1, 128, 28, 28]               0\n       Conv2dAuto-51          [-1, 512, 28, 28]          65,536\n      BatchNorm2d-52          [-1, 512, 28, 28]           1,024\nResNetBottleNeckBlock-53          [-1, 512, 28, 28]               0\n       Conv2dAuto-54          [-1, 128, 28, 28]          65,536\n      BatchNorm2d-55          [-1, 128, 28, 28]             256\n             ReLU-56          [-1, 128, 28, 28]               0\n             ReLU-57          [-1, 128, 28, 28]               0\n       Conv2dAuto-58          [-1, 128, 28, 28]         147,456\n      BatchNorm2d-59          [-1, 128, 28, 28]             256\n             ReLU-60          [-1, 128, 28, 28]               0\n             ReLU-61          [-1, 128, 28, 28]               0\n       Conv2dAuto-62          [-1, 512, 28, 28]          65,536\n      BatchNorm2d-63          [-1, 512, 28, 28]           1,024\nResNetBottleNeckBlock-64          [-1, 512, 28, 28]               0\n       Conv2dAuto-65          [-1, 128, 28, 28]          65,536\n      BatchNorm2d-66          [-1, 128, 28, 28]             256\n             ReLU-67          [-1, 128, 28, 28]               0\n             ReLU-68          [-1, 128, 28, 28]               0\n       Conv2dAuto-69          [-1, 128, 28, 28]         147,456\n      BatchNorm2d-70          [-1, 128, 28, 28]             256\n             ReLU-71          [-1, 128, 28, 28]               0\n             ReLU-72          [-1, 128, 28, 28]               0\n       Conv2dAuto-73          [-1, 512, 28, 28]          65,536\n      BatchNorm2d-74          [-1, 512, 28, 28]           1,024\nResNetBottleNeckBlock-75          [-1, 512, 28, 28]               0\n       Conv2dAuto-76          [-1, 128, 28, 28]          65,536\n      BatchNorm2d-77          [-1, 128, 28, 28]             256\n             ReLU-78          [-1, 128, 28, 28]               0\n             ReLU-79          [-1, 128, 28, 28]               0\n       Conv2dAuto-80          [-1, 128, 28, 28]         147,456\n      BatchNorm2d-81          [-1, 128, 28, 28]             256\n             ReLU-82          [-1, 128, 28, 28]               0\n             ReLU-83          [-1, 128, 28, 28]               0\n       Conv2dAuto-84          [-1, 512, 28, 28]          65,536\n      BatchNorm2d-85          [-1, 512, 28, 28]           1,024\nResNetBottleNeckBlock-86          [-1, 512, 28, 28]               0\n      ResNetLayer-87          [-1, 512, 28, 28]               0\n           Conv2d-88         [-1, 1024, 14, 14]         524,288\n      BatchNorm2d-89         [-1, 1024, 14, 14]           2,048\n       Conv2dAuto-90          [-1, 256, 28, 28]         131,072\n      BatchNorm2d-91          [-1, 256, 28, 28]             512\n             ReLU-92          [-1, 256, 28, 28]               0\n             ReLU-93          [-1, 256, 28, 28]               0\n       Conv2dAuto-94          [-1, 256, 14, 14]         589,824\n      BatchNorm2d-95          [-1, 256, 14, 14]             512\n             ReLU-96          [-1, 256, 14, 14]               0\n             ReLU-97          [-1, 256, 14, 14]               0\n       Conv2dAuto-98         [-1, 1024, 14, 14]         262,144\n      BatchNorm2d-99         [-1, 1024, 14, 14]           2,048\nResNetBottleNeckBlock-100         [-1, 1024, 14, 14]               0\n      Conv2dAuto-101          [-1, 256, 14, 14]         262,144\n     BatchNorm2d-102          [-1, 256, 14, 14]             512\n            ReLU-103          [-1, 256, 14, 14]               0\n            ReLU-104          [-1, 256, 14, 14]               0\n      Conv2dAuto-105          [-1, 256, 14, 14]         589,824\n     BatchNorm2d-106          [-1, 256, 14, 14]             512\n            ReLU-107          [-1, 256, 14, 14]               0\n            ReLU-108          [-1, 256, 14, 14]               0\n      Conv2dAuto-109         [-1, 1024, 14, 14]         262,144\n     BatchNorm2d-110         [-1, 1024, 14, 14]           2,048\nResNetBottleNeckBlock-111         [-1, 1024, 14, 14]               0\n      Conv2dAuto-112          [-1, 256, 14, 14]         262,144\n     BatchNorm2d-113          [-1, 256, 14, 14]             512\n            ReLU-114          [-1, 256, 14, 14]               0\n            ReLU-115          [-1, 256, 14, 14]               0\n      Conv2dAuto-116          [-1, 256, 14, 14]         589,824\n     BatchNorm2d-117          [-1, 256, 14, 14]             512\n            ReLU-118          [-1, 256, 14, 14]               0\n            ReLU-119          [-1, 256, 14, 14]               0\n      Conv2dAuto-120         [-1, 1024, 14, 14]         262,144\n     BatchNorm2d-121         [-1, 1024, 14, 14]           2,048\nResNetBottleNeckBlock-122         [-1, 1024, 14, 14]               0\n      Conv2dAuto-123          [-1, 256, 14, 14]         262,144\n     BatchNorm2d-124          [-1, 256, 14, 14]             512\n            ReLU-125          [-1, 256, 14, 14]               0\n            ReLU-126          [-1, 256, 14, 14]               0\n      Conv2dAuto-127          [-1, 256, 14, 14]         589,824\n     BatchNorm2d-128          [-1, 256, 14, 14]             512\n            ReLU-129          [-1, 256, 14, 14]               0\n            ReLU-130          [-1, 256, 14, 14]               0\n      Conv2dAuto-131         [-1, 1024, 14, 14]         262,144\n     BatchNorm2d-132         [-1, 1024, 14, 14]           2,048\nResNetBottleNeckBlock-133         [-1, 1024, 14, 14]               0\n      Conv2dAuto-134          [-1, 256, 14, 14]         262,144\n     BatchNorm2d-135          [-1, 256, 14, 14]             512\n            ReLU-136          [-1, 256, 14, 14]               0\n            ReLU-137          [-1, 256, 14, 14]               0\n      Conv2dAuto-138          [-1, 256, 14, 14]         589,824\n     BatchNorm2d-139          [-1, 256, 14, 14]             512\n            ReLU-140          [-1, 256, 14, 14]               0\n            ReLU-141          [-1, 256, 14, 14]               0\n      Conv2dAuto-142         [-1, 1024, 14, 14]         262,144\n     BatchNorm2d-143         [-1, 1024, 14, 14]           2,048\nResNetBottleNeckBlock-144         [-1, 1024, 14, 14]               0\n      Conv2dAuto-145          [-1, 256, 14, 14]         262,144\n     BatchNorm2d-146          [-1, 256, 14, 14]             512\n            ReLU-147          [-1, 256, 14, 14]               0\n            ReLU-148          [-1, 256, 14, 14]               0\n      Conv2dAuto-149          [-1, 256, 14, 14]         589,824\n     BatchNorm2d-150          [-1, 256, 14, 14]             512\n            ReLU-151          [-1, 256, 14, 14]               0\n            ReLU-152          [-1, 256, 14, 14]               0\n      Conv2dAuto-153         [-1, 1024, 14, 14]         262,144\n     BatchNorm2d-154         [-1, 1024, 14, 14]           2,048\nResNetBottleNeckBlock-155         [-1, 1024, 14, 14]               0\n     ResNetLayer-156         [-1, 1024, 14, 14]               0\n          Conv2d-157           [-1, 2048, 7, 7]       2,097,152\n     BatchNorm2d-158           [-1, 2048, 7, 7]           4,096\n      Conv2dAuto-159          [-1, 512, 14, 14]         524,288\n     BatchNorm2d-160          [-1, 512, 14, 14]           1,024\n            ReLU-161          [-1, 512, 14, 14]               0\n            ReLU-162          [-1, 512, 14, 14]               0\n      Conv2dAuto-163            [-1, 512, 7, 7]       2,359,296\n     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n            ReLU-165            [-1, 512, 7, 7]               0\n            ReLU-166            [-1, 512, 7, 7]               0\n      Conv2dAuto-167           [-1, 2048, 7, 7]       1,048,576\n     BatchNorm2d-168           [-1, 2048, 7, 7]           4,096\nResNetBottleNeckBlock-169           [-1, 2048, 7, 7]               0\n      Conv2dAuto-170            [-1, 512, 7, 7]       1,048,576\n     BatchNorm2d-171            [-1, 512, 7, 7]           1,024\n            ReLU-172            [-1, 512, 7, 7]               0\n            ReLU-173            [-1, 512, 7, 7]               0\n      Conv2dAuto-174            [-1, 512, 7, 7]       2,359,296\n     BatchNorm2d-175            [-1, 512, 7, 7]           1,024\n            ReLU-176            [-1, 512, 7, 7]               0\n            ReLU-177            [-1, 512, 7, 7]               0\n      Conv2dAuto-178           [-1, 2048, 7, 7]       1,048,576\n     BatchNorm2d-179           [-1, 2048, 7, 7]           4,096\nResNetBottleNeckBlock-180           [-1, 2048, 7, 7]               0\n      Conv2dAuto-181            [-1, 512, 7, 7]       1,048,576\n     BatchNorm2d-182            [-1, 512, 7, 7]           1,024\n            ReLU-183            [-1, 512, 7, 7]               0\n            ReLU-184            [-1, 512, 7, 7]               0\n      Conv2dAuto-185            [-1, 512, 7, 7]       2,359,296\n     BatchNorm2d-186            [-1, 512, 7, 7]           1,024\n            ReLU-187            [-1, 512, 7, 7]               0\n            ReLU-188            [-1, 512, 7, 7]               0\n      Conv2dAuto-189           [-1, 2048, 7, 7]       1,048,576\n     BatchNorm2d-190           [-1, 2048, 7, 7]           4,096\nResNetBottleNeckBlock-191           [-1, 2048, 7, 7]               0\n     ResNetLayer-192           [-1, 2048, 7, 7]               0\n   ResNetEncoder-193           [-1, 2048, 7, 7]               0\nAdaptiveAvgPool2d-194           [-1, 2048, 1, 1]               0\n          Linear-195                 [-1, 4000]       8,196,000\n   ResnetDecoder-196                 [-1, 4000]               0\n================================================================\nTotal params: 31,704,032\nTrainable params: 31,704,032\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.57\nForward/backward pass size (MB): 281.83\nParams size (MB): 120.94\nEstimated Total Size (MB): 403.34\n----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "model = resnet50(in_channels=3, n_classes=4000)\n",
    "summary(model, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MobileNetV2():\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 n_in_ch_bn: int,\n",
    "                 ls_out_ch_bn: list,\n",
    "                 ls_n_rep_bn: list,\n",
    "                 ls_stride_bn: list,\n",
    "                 ls_exp_fct_t_bn: list,\n",
    "                 n_embeddings: int,\n",
    "                 n_classes: int,\n",
    "                 lr: float,\n",
    "                 lr_decay: float,\n",
    "                 n_lr_decay_steps: int,\n",
    "                 center_loss: bool,\n",
    "                 lr_cl: float,\n",
    "                 alpha_cl: float,\n",
    "                 n_epochs: int,\n",
    "                 eval_steps: int):\n",
    "\n",
    "        # Architecture parameters\n",
    "        self.n_in_ch_bn = n_in_ch_bn\n",
    "        self.ls_out_ch_bn = ls_out_ch_bn\n",
    "        self.ls_n_rep_bn = ls_n_rep_bn\n",
    "        self.ls_stride_bn = ls_stride_bn\n",
    "        self.ls_exp_fct_t_bn = ls_exp_fct_t_bn\n",
    "        self.n_embeddings = n_embeddings\n",
    "        self.n_classes = n_classes\n",
    "        self.center_loss = center_loss\n",
    "\n",
    "        # Optimization parameters\n",
    "        self.lr = lr\n",
    "        self.lr_decay = lr_decay\n",
    "        self.n_lr_decay_steps = n_lr_decay_steps\n",
    "        self.lr_cl = lr_cl\n",
    "        self.alpha_cl = alpha_cl\n",
    "        self.n_epochs = n_epochs\n",
    "        self.eval_steps = eval_steps\n",
    "\n",
    "        self.model = _MobileNetV2(n_in_ch_bn=n_in_ch_bn,\n",
    "                                  ls_out_ch_bn=ls_out_ch_bn,\n",
    "                                  ls_n_rep_bn=ls_n_rep_bn,\n",
    "                                  ls_stride_bn=ls_stride_bn,\n",
    "                                  ls_exp_fct_t_bn=ls_exp_fct_t_bn,\n",
    "                                  n_embeddings=n_embeddings,\n",
    "                                  n_classes=n_classes)\n",
    "\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    def fit(self, train_loader, val_c_loader, val_v_loader):\n",
    "\n",
    "        print(\"=\"*30 + 'Start Fitting' + \"=\"*30)\n",
    "        self.model.to(self.device)\n",
    "        self.model.train()\n",
    "        \n",
    "        cross_entroypy_loss_f = nn.CrossEntropyLoss()\n",
    "        center_loss_f = CenterLoss(num_classes=self.n_classes,\n",
    "                                   feat_dim=self.n_embeddings,\n",
    "                                   use_gpu=torch.cuda.is_available())\n",
    "    \n",
    "        # optimizer = Adam(self.model.parameters(), \n",
    "        #                  lr=self.lr, \n",
    "        #                  weight_decay=0.00004)\n",
    "\n",
    "        # optimizer_centerloss = Adam(center_loss_f.parameters(),\n",
    "        #                             lr=self.lr_cl)\n",
    "\n",
    "        optimizer = SGD(self.model.parameters(), \n",
    "                        lr=self.lr, \n",
    "                        weight_decay=0.00004,\n",
    "                        momentum=0.9)\n",
    "\n",
    "        optimizer_centerloss = SGD(center_loss_f.parameters(),\n",
    "                                   lr=self.lr_cl)                            \n",
    "\n",
    "        scheduler = StepLR(optimizer=optimizer, \n",
    "                           step_size=self.n_epochs//self.n_lr_decay_steps,\n",
    "                           gamma=self.lr_decay)\n",
    "        \n",
    "        self.train_loss = -1\n",
    "        self.val_c_loss = -1\n",
    "        self.train_c_acc = 0\n",
    "        self.val_c_acc = 0\n",
    "        self.val_v_acc = 0\n",
    "        self.trajectories = {'epoch': [],\n",
    "                             'train_loss': [],\n",
    "                             'train_c_acc': [],\n",
    "                             'val_c_loss': [],\n",
    "                             'val_c_acc': [],\n",
    "                             'val_v_acc':[]}\n",
    "\n",
    "        for epoch in range(self.n_epochs):\n",
    "            \n",
    "            train_loss = 0\n",
    "            train_correct_predictions = 0\n",
    "            train_total_predictions = 0\n",
    "\n",
    "            for batch_idx, (img, label) in enumerate(train_loader):\n",
    "                img = img.to(self.device)\n",
    "                label = label.to(self.device)\n",
    "                \n",
    "                embeddings, cl_output = self.model(img)\n",
    "\n",
    "                if self.center_loss == True:\n",
    "                    loss = self.alpha_cl * center_loss_f(embeddings, label) + \\\n",
    "                       cross_entroypy_loss_f(cl_output, label)\n",
    "\n",
    "                else:\n",
    "                    loss = cross_entroypy_loss_f(cl_output, label)\n",
    "\n",
    "                predicted = torch.argmax(cl_output.data, 1)\n",
    "                train_correct_predictions += (predicted == label).sum().item()\n",
    "                train_total_predictions += len(label)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                if self.center_loss == True: \n",
    "                    optimizer_centerloss.zero_grad()\n",
    "\n",
    "                loss.backward()\n",
    "                \n",
    "                if self.center_loss == True:\n",
    "                    for p in center_loss_f.parameters():\n",
    "                        p.grad.data *= (1./self.alpha_cl)\n",
    "                \n",
    "                optimizer.step()\n",
    "\n",
    "                if self.center_loss == True:\n",
    "                    optimizer_centerloss.step()\n",
    "\n",
    "                scheduler.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "            \n",
    "            train_loss /= len(train_loader)\n",
    "            train_c_acc = train_correct_predictions/train_total_predictions     \n",
    "\n",
    "            if epoch % self.eval_steps == 0:\n",
    "                val_c_loss, val_c_acc, val_v_acc = \\\n",
    "                    self.evaluate_performance(val_c_loader, \n",
    "                                              val_v_loader)\n",
    "        \n",
    "                self.trajectories['epoch'].append(epoch)\n",
    "                self.trajectories['train_loss'].append(train_loss)\n",
    "                self.trajectories['train_c_acc'].append(train_c_acc)\n",
    "                self.trajectories['val_c_loss'].append(val_c_loss)\n",
    "                self.trajectories['val_c_acc'].append(val_c_acc)\n",
    "                self.trajectories['val_v_acc'].append(val_v_acc)\n",
    "\n",
    "                display_str = f'epoch: {epoch} '\n",
    "                display_str += f'train_loss: {np.round(train_loss,4)} '\n",
    "                display_str += f'train_c_acc: {np.round(train_c_acc,4):.2%} '\n",
    "                display_str += f'val_c_loss: {np.round(val_c_loss,4)} '\n",
    "                display_str += f'val_c_acc: {np.round(val_c_acc,4):.2%} '\n",
    "                display_str += f'val_v_acc: {np.round(val_v_acc,4):.2%} '\n",
    "                print(display_str)\n",
    "\n",
    "                if self.val_c_loss > val_c_loss: self.val_c_loss = val_c_loss\n",
    "                if self.train_loss > train_loss: self.train_loss = train_loss\n",
    "                if self.train_c_acc < train_c_acc: self.train_c_acc = train_c_acc\n",
    "                if self.val_c_acc < val_c_acc: self.val_c_acc = val_c_acc\n",
    "                if self.val_v_acc < val_v_acc: self.val_v_acc = val_v_acc\n",
    "        \n",
    "        print(\"=\"*72+\"\\n\")\n",
    "\n",
    "\n",
    "    def evaluate_performance(self, val_c_loader, val_v_loader):\n",
    "\n",
    "        cross_entroypy_loss_f = nn.CrossEntropyLoss()\n",
    "        center_loss_f = CenterLoss(num_classes=self.n_classes,\n",
    "                                   feat_dim=self.n_embeddings,\n",
    "                                   use_gpu=torch.cuda.is_available())\n",
    "        \n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "        val_c_loss = 0.0\n",
    "        total_predictions = 0.0\n",
    "        correct_predictions = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (img, label) in enumerate(val_c_loader):\n",
    "                img = img.to(self.device)\n",
    "                label = label.to(self.device)\n",
    "\n",
    "                embeddings, cl_output = self.model(img)\n",
    "\n",
    "                if self.center_loss == True:\n",
    "                    loss = self.alpha_cl * center_loss_f(embeddings, label) + \\\n",
    "                       cross_entroypy_loss_f(cl_output, label)\n",
    "\n",
    "                else:\n",
    "                    loss = cross_entroypy_loss_f(cl_output, label)\n",
    "\n",
    "                loss = loss.detach()\n",
    "                val_c_loss += loss.item()\n",
    "\n",
    "                predicted = torch.argmax(cl_output.data, 1)\n",
    "                total_predictions += len(label)\n",
    "                correct_predictions += (predicted == label).sum().item()\n",
    "\n",
    "        val_c_loss /= len(val_c_loader) \n",
    "        val_c_acc = correct_predictions/total_predictions\n",
    "\n",
    "        similarity = np.array([])\n",
    "        ver_bool = np.array([])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (img_0, img_1, target) in enumerate(val_v_loader):\n",
    "                img_0 = img_0.to(self.device)\n",
    "                img_1 = img_1.to(self.device)\n",
    "\n",
    "                emb_0 = self.model(img_0)[0]\n",
    "                emb_1 = self.model(img_1)[0]\n",
    "\n",
    "                sim_score = cosine_similarity(emb_0, emb_1)\n",
    "                similarity = np.append(similarity, sim_score.cpu().numpy().reshape(-1))\n",
    "                ver_bool = np.append(ver_bool, target)\n",
    "            \n",
    "        val_v_acc = roc_auc_score(ver_bool, similarity)\n",
    "\n",
    "        return val_c_loss, val_c_acc, val_v_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from axa_hw2p2.datasets import FaceClassificationDataset, FaceVerificationDataset\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "sample_train = np.array(range(6))\n",
    "sample_val_c = list(range(2))\n",
    "sample_val_c = np.array([sample_train[i] for i in sample_val_c])\n",
    "sample_val_v = np.array(range(2))\n",
    "\n",
    "train_dataset = FaceClassificationDataset(sample_train, mode='train')\n",
    "val_c_dataset = FaceClassificationDataset(sample_val_c, mode='val')\n",
    "val_v_dataset = FaceVerificationDataset(sample_val_v, mode='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Architecture parameters\n",
    "mc = {}\n",
    "mc['n_in_ch_bn'] = 3\n",
    "mc['ls_out_ch_bn'] = [16, 24, 32, 64, 96, 160, 320]\n",
    "mc['ls_n_rep_bn'] = [1, 2, 3, 4, 3, 3, 1]\n",
    "mc['ls_stride_bn'] = [1, 2, 2, 2, 1, 2, 1]\n",
    "mc['ls_exp_fct_t_bn'] = [1, 6, 6, 6, 6, 6, 6]\n",
    "mc['n_embeddings'] = 1280\n",
    "mc['n_classes'] = len(np.unique(train_dataset.labels))\n",
    "\n",
    "# Optimization and regularization parameters\n",
    "mc['batch_size'] = 64\n",
    "mc['lr'] = 0.001\n",
    "mc['lr_decay'] = 0.99\n",
    "mc['n_lr_decay_steps'] = 4\n",
    "mc['lr_cl'] = 0.5\n",
    "mc['alpha_cl'] = 0.01\n",
    "mc['n_epochs'] = 16\n",
    "mc['eval_steps'] = 4\n",
    "\n",
    "print(77*'=')\n",
    "print(pd.Series(mc))\n",
    "print(77*'=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MobileNetV2(n_in_ch_bn=mc['n_in_ch_bn'],\n",
    "                    ls_out_ch_bn=mc['ls_out_ch_bn'],\n",
    "                    ls_n_rep_bn=mc['ls_n_rep_bn'],\n",
    "                    ls_stride_bn=mc['ls_stride_bn'],\n",
    "                    ls_exp_fct_t_bn=mc['ls_exp_fct_t_bn'],\n",
    "                    n_embeddings=mc['n_embeddings'],\n",
    "                    n_classes=mc['n_classes'],\n",
    "                    lr=mc['lr'],\n",
    "                    lr_decay=mc['lr_decay'],\n",
    "                    n_lr_decay_steps=mc['n_lr_decay_steps'],\n",
    "                    lr_cl=mc['lr_cl'],\n",
    "                    alpha_cl=mc['alpha_cl'],\n",
    "                    n_epochs=mc['n_epochs'],\n",
    "                    eval_steps=mc['eval_steps'])\n",
    "print(model.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, \n",
    "                          shuffle=True, \n",
    "                          batch_size=mc['batch_size'], \n",
    "                          drop_last=True)\n",
    "\n",
    "val_c_loader = DataLoader(val_c_dataset, \n",
    "                          shuffle=False, \n",
    "                          batch_size=1, \n",
    "                          drop_last=True)\n",
    "                          \n",
    "val_v_loader = DataLoader(val_v_dataset, \n",
    "                          shuffle=False, \n",
    "                          batch_size=1, \n",
    "                          drop_last=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_loader=train_loader,\n",
    "          val_c_loader=val_c_loader,\n",
    "          val_v_loader=val_v_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('idl_ubuntu': conda)",
   "metadata": {
    "interpreter": {
     "hash": "90fe67124204a04bb5d130edc44abf452890e25295d02a40ff695cfcd1c7864c"
    }
   },
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
