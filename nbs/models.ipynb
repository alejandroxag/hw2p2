{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    ">Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class _FaceClassificationCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 n_ch_input,\n",
    "                 n_classes):\n",
    "        super(_FaceClassificationCNN, self).__init__()\n",
    "\n",
    "        self.n_ch_input = n_ch_input\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        self.conv_layer_1 = nn.Conv2d(in_channels=n_ch_input,\n",
    "                                      out_channels=128,\n",
    "                                      kernel_size=7)\n",
    "        self.relu_layer_1 = nn.ReLU()\n",
    "        self.pool_layer_1 = nn.MaxPool2d(kernel_size=2,\n",
    "                                         stride=2)\n",
    "\n",
    "        self.conv_layer_2 = nn.Conv2d(in_channels=128,\n",
    "                                      out_channels=64,\n",
    "                                      kernel_size=7)\n",
    "        self.relu_layer_2 = nn.ReLU()\n",
    "        self.pool_layer_2 = nn.MaxPool2d(kernel_size=2,\n",
    "                                         stride=2)\n",
    "\n",
    "        self.relu_layer_3 = nn.ReLU()\n",
    "        self.linear_layer_3 = nn.Linear(in_features=64*11*11,\n",
    "                                        out_features=n_classes)\n",
    "        \n",
    "        self.relu_layer_4 = nn.ReLU()\n",
    "        self.linear_layer_4 = nn.Linear(in_features=n_classes,\n",
    "                                        out_features=n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layer_1(x)\n",
    "        x = self.relu_layer_1(x)\n",
    "        x = self.pool_layer_1(x)\n",
    "        x = self.conv_layer_2(x)\n",
    "        x = self.relu_layer_2(x)\n",
    "        x = self.pool_layer_2(x)\n",
    "        x = x.view(-1, 64*11*11)\n",
    "        x = self.relu_layer_3(x)\n",
    "        x = self.linear_layer_3(x)\n",
    "        x = self.relu_layer_4(x)\n",
    "        x = self.linear_layer_4(x)\n",
    "        return x\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class FaceClassificationCNN():\n",
    "    def __init__(self,\n",
    "                 n_ch_input,\n",
    "                 n_classes,\n",
    "                 lr,\n",
    "                 lr_decay,\n",
    "                 n_lr_decay_steps,\n",
    "                 n_epochs,\n",
    "                 eval_steps):\n",
    "\n",
    "        # Architecture parameters\n",
    "        self.n_ch_input = n_ch_input\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        # Optimization parameters\n",
    "        self.lr = lr\n",
    "        self.lr_decay = lr_decay\n",
    "        self.n_lr_decay_steps = n_lr_decay_steps\n",
    "        self.n_epochs = n_epochs\n",
    "        self.eval_steps = eval_steps\n",
    "\n",
    "        self.model = _FaceClassificationCNN(n_ch_input=n_ch_input,\n",
    "                                            n_classes=n_classes)\n",
    "\n",
    "        # self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    def fit(self, train_loader, val_loader):\n",
    "        print(\"=\"*30 + 'Start Fitting' + \"=\"*30)\n",
    "        # self.model.to(self.device)\n",
    "        self.model.train()\n",
    "        loss_function = nn.CrossEntropyLoss()\n",
    "        optimizer = Adam(self.model.parameters(), \n",
    "                         lr=self.lr, \n",
    "                         weight_decay=0.0005)\n",
    "        scheduler = StepLR(optimizer=optimizer, \n",
    "                           step_size=self.n_epochs//self.n_lr_decay_steps,\n",
    "                           gamma=self.lr_decay)\n",
    "        \n",
    "        self.train_loss = -1\n",
    "        self.val_loss = -1\n",
    "        self.trajectories = {'epoch': [],\n",
    "                             'train_loss': [],\n",
    "                             'val_loss': []}\n",
    "\n",
    "        for epoch in range(self.n_epochs):\n",
    "            \n",
    "            train_loss = 0\n",
    "\n",
    "            for batch_idx, (img, label) in enumerate(train_loader):\n",
    "                \n",
    "                # img = img.to(self.device)\n",
    "                # label = label.to(self.device)\n",
    "                \n",
    "                output = self.model(img)\n",
    "\n",
    "                loss = loss_function(output, label)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "            \n",
    "            train_loss /= len(train_loader)         \n",
    "\n",
    "            if epoch % self.eval_steps == 0:\n",
    "                val_loss, val_accuracy = self.evaluate_performance(val_loader)\n",
    "        \n",
    "                self.trajectories['epoch'].append(epoch)\n",
    "                self.trajectories['train_loss'].append(train_loss)\n",
    "                self.trajectories['val_loss'].append(val_loss)\n",
    "\n",
    "                display_str = f'epoch: {epoch} '\n",
    "                display_str += f'train_loss: {np.round(train_loss,4)} '\n",
    "                display_str += f'val_loss: {np.round(val_loss,4)} '\n",
    "                display_str += f'val_accuracy: {np.round(val_accuracy,4):.2%}'\n",
    "                print(display_str)\n",
    "\n",
    "                if self.val_loss > val_loss: self.val_loss = val_loss\n",
    "                if self.train_loss > train_loss: self.train_loss = train_loss\n",
    "        \n",
    "        print(\"=\"*72+\"\\n\")\n",
    "\n",
    "\n",
    "    def evaluate_performance(self, val_loader):\n",
    "\n",
    "        loss_function = nn.CrossEntropyLoss()\n",
    "        # self.model.to(device)\n",
    "        self.model.eval()\n",
    "\n",
    "        val_loss = 0.0\n",
    "        total_predictions = 0.0\n",
    "        correct_predictions = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (img, label) in enumerate(val_loader):\n",
    "                \n",
    "                # img = img.to(device)\n",
    "                # label = label.to(device)\n",
    "                outputs = self.model(img)\n",
    "                loss = loss_function(outputs, label).detach()\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                predicted = torch.argmax(outputs, 1)\n",
    "                total_predictions += img.size(0)\n",
    "                correct_predictions += (predicted == label).sum().item()\n",
    "\n",
    "        val_loss /= len(val_loader) \n",
    "        acc = correct_predictions/total_predictions\n",
    "        \n",
    "        return val_loss, acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from axa_hw2p2.datasets import FaceClassificationDataset\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "sample = np.array(range(20))\n",
    "train_dataset = FaceClassificationDataset(sample, mode='train')\n",
    "val_dataset = FaceClassificationDataset(sample, mode='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Architecture parameters\n",
    "mc = {}\n",
    "mc['n_ch_input'] = 3\n",
    "mc['n_classes'] = len(np.unique([t[1] for t in train_dataset]))\n",
    "\n",
    "# Optimization and regularization parameters\n",
    "mc['batch_size'] = 1\n",
    "mc['lr'] = 0.001\n",
    "mc['lr_decay'] = 1\n",
    "mc['n_lr_decay_steps'] = 2\n",
    "mc['n_epochs'] = 16\n",
    "mc['eval_steps'] = 4\n",
    "\n",
    "print(77*'=')\n",
    "print(pd.Series(mc))\n",
    "print(77*'=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FaceClassificationCNN(n_ch_input=mc['n_ch_input'],\n",
    "                              n_classes=mc['n_classes'],\n",
    "                              lr=mc['lr'],\n",
    "                              lr_decay=float(mc['lr_decay']),\n",
    "                              n_lr_decay_steps=int(mc['n_lr_decay_steps']),\n",
    "                              n_epochs=mc['n_epochs'],\n",
    "                              eval_steps=mc['eval_steps'])\n",
    "print(model.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, \n",
    "                          shuffle=True, \n",
    "                          batch_size=mc['batch_size'], \n",
    "                          drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, \n",
    "                        shuffle=False, \n",
    "                        batch_size=mc['batch_size'], \n",
    "                        drop_last=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_loader=train_loader, val_loader=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idl_ubuntu",
   "language": "python",
   "name": "idl_ubuntu"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
