{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    ">Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from axa_hw2p2.losses import CenterLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class _BottleNeck(nn.Module):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 n_input_ch: int,\n",
    "                 n_output_ch: int,\n",
    "                 stride: int,\n",
    "                 exp_fct_t: int):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        super(_BottleNeck, self).__init__()\n",
    "        self.n_input_ch = n_input_ch\n",
    "        self.n_output_ch = n_output_ch\n",
    "        self.stride = stride\n",
    "\n",
    "        # Expansion block: \n",
    "        # (batch_size, height, width, n_input_ch) -> \n",
    "        # (batch_size, height, width, exp_fct_t*n_input_ch)\n",
    "        # kernel size: 1, stride: 1, padding: 0, groups: 1.\n",
    "        exp_block = []\n",
    "        exp_block.append(nn.Conv2d(in_channels=n_input_ch,\n",
    "                                   out_channels=exp_fct_t*n_input_ch,\n",
    "                                   kernel_size=1,\n",
    "                                   stride=1,\n",
    "                                   padding=0,\n",
    "                                   groups=1,\n",
    "                                   bias=False))\n",
    "        exp_block.append(nn.BatchNorm2d(num_features=exp_fct_t*n_input_ch))\n",
    "        exp_block.append(nn.ReLU6())\n",
    "\n",
    "        # Depthwise convolutional block: \n",
    "        # (batch_size, height, width, exp_fct_t*n_input_ch) -> \n",
    "        # (batch_size, height/stride, width/stride, exp_fct_t*n_input_ch)\n",
    "        # kernel size: 3, stride: stride, \n",
    "        # padding: 1, groups: exp_fct_t*n_input_ch.\n",
    "        dw_conv_block = []\n",
    "        dw_conv_block.append(nn.Conv2d(in_channels=exp_fct_t*n_input_ch,\n",
    "                                       out_channels=exp_fct_t*n_input_ch,\n",
    "                                       kernel_size=3,\n",
    "                                       stride=stride,\n",
    "                                       padding=1,\n",
    "                                       groups=exp_fct_t*n_input_ch, \n",
    "                                       bias=False))\n",
    "        dw_conv_block.append(nn.BatchNorm2d(num_features=exp_fct_t*n_input_ch))\n",
    "        dw_conv_block.append(nn.ReLU6())\n",
    "\n",
    "        # Depthwise convolutional block: \n",
    "        # (batch_size, height, width, exp_fct_t*n_input_ch) -> \n",
    "        # (batch_size, height/stride, width/stride, n_output_ch)\n",
    "        # kernel size: 1, stride: 1, padding: 0, groups: 1.\n",
    "        proj_block = []\n",
    "        proj_block.append(nn.Conv2d(in_channels=exp_fct_t*n_input_ch,\n",
    "                                    out_channels=n_output_ch,\n",
    "                                    kernel_size=1,\n",
    "                                    stride=1,\n",
    "                                    padding=0,\n",
    "                                    groups=1, \n",
    "                                    bias=False))\n",
    "        proj_block.append(nn.BatchNorm2d(num_features=n_output_ch))\n",
    "\n",
    "        self.block = exp_block + dw_conv_block + proj_block\n",
    "        self.block = nn.Sequential(*self.block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        if self.stride == 1 and self.n_input_ch == self.n_output_ch:\n",
    "            return x + self.block(x)\n",
    "        else:\n",
    "            return self.block(x)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class _MobileNetV2(nn.Module):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 n_in_ch_bn: int,\n",
    "                 ls_out_ch_bn: list,\n",
    "                 ls_n_rep_bn: list,\n",
    "                 ls_stride_bn: list,\n",
    "                 ls_exp_fct_t_bn: list,\n",
    "                 n_embeddings: int,\n",
    "                 n_classes: int):\n",
    "        \n",
    "        super(_MobileNetV2, self).__init__()\n",
    "\n",
    "        assert len(ls_out_ch_bn) == len(ls_n_rep_bn)\n",
    "        assert len(ls_n_rep_bn) == len(ls_stride_bn)\n",
    "        assert len(ls_stride_bn) == len(ls_exp_fct_t_bn)\n",
    "\n",
    "        # Initial fully convolution block\n",
    "        # (batch_size, 64, 64, 3) ->\n",
    "        # (batch_size, 64, 64, n_in_ch_bn)\n",
    "        # kernel size: 1, stride: 1, padding: 0, groups: 1.\n",
    "        # (stride is 1 instead of two because images are small (64x64))\n",
    "        block1 = []\n",
    "        block1.append(nn.Conv2d(in_channels=3,\n",
    "                                out_channels=n_in_ch_bn,\n",
    "                                kernel_size=3,\n",
    "                                stride=1,\n",
    "                                padding=0,\n",
    "                                groups=1,\n",
    "                                bias=False))\n",
    "        block1.append(nn.BatchNorm2d(n_in_ch_bn))\n",
    "        block1.append(nn.ReLU6())\n",
    "\n",
    "        # Bottlenecks\n",
    "        bottlenecks = []\n",
    "        n_input_ch = n_in_ch_bn\n",
    "\n",
    "        for i in range(len(ls_out_ch_bn)):\n",
    "            \n",
    "            c = ls_out_ch_bn[i]\n",
    "            n = ls_n_rep_bn[i]\n",
    "            s = ls_stride_bn[i]\n",
    "            t = ls_exp_fct_t_bn[i]\n",
    "\n",
    "            for j in range(n):\n",
    "                \n",
    "                if j == 0: stride = 1\n",
    "                else: stride = s\n",
    "                bottlenecks.append(_BottleNeck(n_input_ch=n_input_ch,\n",
    "                                               n_output_ch=c,\n",
    "                                               stride=stride,\n",
    "                                               exp_fct_t=t))\n",
    "                n_input_ch = c\n",
    "        \n",
    "        # Last 1x1 convolution block\n",
    "        blockn = []\n",
    "        blockn.append(nn.Conv2d(in_channels=n_input_ch,\n",
    "                                out_channels=n_embeddings,\n",
    "                                kernel_size=1,\n",
    "                                stride=1,\n",
    "                                padding=0,\n",
    "                                groups=1,\n",
    "                                bias=False))\n",
    "        blockn.append(nn.BatchNorm2d(n_embeddings))\n",
    "        blockn.append(nn.ReLU6())\n",
    "\n",
    "        self.net = block1 + bottlenecks + blockn\n",
    "        self.net = nn.Sequential(*self.net)\n",
    "        self.classifier = nn.Linear(in_features=n_embeddings, \n",
    "                                    out_features=n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        x = self.net(x)\n",
    "        x = nn.adaptive_avg_pool2d(x, 1)\n",
    "        embeddings = x.view(1, -1)\n",
    "        cl_output = self.classifier(x)\n",
    "        \n",
    "        return embeddings, cl_output\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (2): ReLU6()\n  (3): _BottleNeck(\n    (block): Sequential(\n      (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU6()\n      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU6()\n      (6): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (4): _BottleNeck(\n    (block): Sequential(\n      (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU6()\n      (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n      (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU6()\n      (6): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (5): _BottleNeck(\n    (block): Sequential(\n      (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU6()\n      (3): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n      (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU6()\n      (6): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (6): _BottleNeck(\n    (block): Sequential(\n      (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU6()\n      (3): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n      (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU6()\n      (6): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (7): _BottleNeck(\n    (block): Sequential(\n      (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU6()\n      (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n      (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU6()\n      (6): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (8): _BottleNeck(\n    (block): Sequential(\n      (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU6()\n      (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n      (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU6()\n      (6): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (9): _BottleNeck(\n    (block): Sequential(\n      (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU6()\n      (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n      (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU6()\n      (6): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (10): _BottleNeck(\n    (block): Sequential(\n      (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU6()\n      (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n      (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU6()\n      (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (11): _BottleNeck(\n    (block): Sequential(\n      (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU6()\n      (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n      (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU6()\n      (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (12): _BottleNeck(\n    (block): Sequential(\n      (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU6()\n      (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n      (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU6()\n      (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (13): _BottleNeck(\n    (block): Sequential(\n      (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU6()\n      (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n      (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU6()\n      (6): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (14): _BottleNeck(\n    (block): Sequential(\n      (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU6()\n      (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n      (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU6()\n      (6): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (15): _BottleNeck(\n    (block): Sequential(\n      (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU6()\n      (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n      (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU6()\n      (6): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (16): _BottleNeck(\n    (block): Sequential(\n      (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU6()\n      (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n      (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU6()\n      (6): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (17): _BottleNeck(\n    (block): Sequential(\n      (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU6()\n      (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=960, bias=False)\n      (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU6()\n      (6): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (18): _BottleNeck(\n    (block): Sequential(\n      (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU6()\n      (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=960, bias=False)\n      (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU6()\n      (6): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (19): _BottleNeck(\n    (block): Sequential(\n      (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU6()\n      (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n      (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU6()\n      (6): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (7): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (20): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (21): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (22): ReLU6()\n)\n"
     ]
    }
   ],
   "source": [
    "# Standard MobileNetV2 architecture\n",
    "\n",
    "n_in_ch_bn = 32\n",
    "ls_out_ch_bn = [16, 24, 32, 64, 96, 160, 320]\n",
    "ls_n_rep_bn = [1, 2, 3, 4, 3, 3, 1]\n",
    "ls_stride_bn = [1, 2, 2, 2, 1, 2, 1]\n",
    "ls_exp_fct_t_bn = [1, 6, 6, 6, 6, 6, 6]\n",
    "n_embeddings = 1280\n",
    "n_classes = 4000\n",
    "\n",
    "model1 = _MobileNetV2(n_in_ch_bn=n_in_ch_bn,\n",
    "                      ls_out_ch_bn=ls_out_ch_bn,\n",
    "                      ls_n_rep_bn=ls_n_rep_bn,\n",
    "                      ls_stride_bn=ls_stride_bn,\n",
    "                      ls_exp_fct_t_bn=ls_exp_fct_t_bn,\n",
    "                      n_embeddings=n_embeddings,\n",
    "                      n_classes=n_classes)\n",
    "\n",
    "print(model1.net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "# n_in_ch_bn: int,\n",
    "#                  ls_out_ch_bn: list,\n",
    "#                  ls_n_rep_bn: list,\n",
    "#                  ls_stride_bn: list,\n",
    "#                  ls_exp_fct_t_bn: list,\n",
    "#                  nembeddings: int,\n",
    "#                  n_classes: int\n",
    "class MobileNetV2():\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 n_in_ch_bn: int,\n",
    "                 ls_out_ch_bn: list,\n",
    "                 ls_n_rep_bn: list,\n",
    "                 ls_stride_bn: list,\n",
    "                 ls_exp_fct_t_bn: list,\n",
    "                 nembeddings: int,\n",
    "                 n_classes: int,\n",
    "                 lr: float,\n",
    "                 lr_decay: float,\n",
    "                 lr_cl: float,\n",
    "                 alpha_cl: float,\n",
    "                 n_lr_decay_steps: int,\n",
    "                 n_epochs: int,\n",
    "                 eval_steps: int):\n",
    "\n",
    "        # Architecture parameters\n",
    "        self.n_in_ch_bn = n_in_ch_bn\n",
    "        self.ls_out_ch_bn = ls_out_ch_bn\n",
    "        self.ls_n_rep_bn = ls_n_rep_bn\n",
    "        self.ls_stride_bn = ls_stride_bn\n",
    "        self.ls_exp_fct_t_bn = ls_exp_fct_t_bn\n",
    "        self.n_embeddings = n_embeddings\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        # Optimization parameters\n",
    "        self.lr = lr\n",
    "        self.lr_decay = lr_decay\n",
    "        self.n_lr_decay_steps = n_lr_decay_steps\n",
    "        self.lr_cl = lr_cl\n",
    "        self.alpha_cl = alpha_cl\n",
    "        self.n_epochs = n_epochs\n",
    "        self.eval_steps = eval_steps\n",
    "\n",
    "        self.model = _MobileNetV2(n_in_ch_bn=n_in_ch_bn,\n",
    "                                  ls_out_ch_bn=ls_out_ch_bn,\n",
    "                                  ls_n_rep_bn=ls_n_rep_bn,\n",
    "                                  ls_stride_bn=ls_stride_bn,\n",
    "                                  ls_exp_fct_t_bn=ls_exp_fct_t_bn,\n",
    "                                  n_embeddings=n_embeddings,\n",
    "                                  n_classes=n_classes)\n",
    "\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    def fit(self, train_loader, val_loader):\n",
    "\n",
    "        print(\"=\"*30 + 'Start Fitting' + \"=\"*30)\n",
    "        self.model.to(self.device)\n",
    "        self.model.train()\n",
    "        \n",
    "        cross_entroypy_loss_f = nn.CrossEntropyLoss()\n",
    "        center_loss_f = CenterLoss(num_classes=n_classes,\n",
    "                                 feat_dim=n_embeddings,\n",
    "                                 use_gpu=torch.cuda.is_available())\n",
    "    \n",
    "        optimizer = Adam(self.model.parameters(), \n",
    "                         lr=self.lr, \n",
    "                         weight_decay=0.0005)\n",
    "        optimizer_centerloss = Adam(center_loss_f.parameters(),\n",
    "                                    lr=lr_cl)\n",
    "\n",
    "        scheduler = StepLR(optimizer=optimizer, \n",
    "                           step_size=self.n_epochs//self.n_lr_decay_steps,\n",
    "                           gamma=self.lr_decay)\n",
    "        \n",
    "        self.train_loss = -1\n",
    "        self.val_loss = -1\n",
    "        self.trajectories = {'epoch': [],\n",
    "                             'train_loss': [],\n",
    "                             'val_loss': []}\n",
    "\n",
    "        for epoch in range(self.n_epochs):\n",
    "            \n",
    "            train_loss = 0\n",
    "\n",
    "            for batch_idx, (img, label) in enumerate(train_loader):\n",
    "                \n",
    "                img = img.to(self.device)\n",
    "                label = label.to(self.device)\n",
    "                \n",
    "                embeddings, cl_output = self.model(img)\n",
    "                loss = alpha_cl * center_loss_f(cl_output, label) + \\\n",
    "                       cross_entroypy_loss_f(cl_output, label)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                optimizer_centerloss.zero_grad()\n",
    "                loss.backward()\n",
    "                for p in center_loss_f.parameters():\n",
    "                    p.grad.data *= (1./alpha_cl)\n",
    "\n",
    "                optimizer.step()\n",
    "                optimizer_centerloss.step()\n",
    "                scheduler.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "            \n",
    "            train_loss /= len(train_loader)         \n",
    "\n",
    "            if epoch % self.eval_steps == 0:\n",
    "                val_loss, val_accuracy = self.evaluate_performance(val_loader)\n",
    "        \n",
    "                self.trajectories['epoch'].append(epoch)\n",
    "                self.trajectories['train_loss'].append(train_loss)\n",
    "                self.trajectories['val_loss'].append(val_loss)\n",
    "\n",
    "                display_str = f'epoch: {epoch} '\n",
    "                display_str += f'train_loss: {np.round(train_loss,4)} '\n",
    "                display_str += f'val_loss: {np.round(val_loss,4)} '\n",
    "                display_str += f'val_accuracy: {np.round(val_accuracy,4):.2%}'\n",
    "                print(display_str)\n",
    "\n",
    "                if self.val_loss > val_loss: self.val_loss = val_loss\n",
    "                if self.train_loss > train_loss: self.train_loss = train_loss\n",
    "        \n",
    "        print(\"=\"*72+\"\\n\")\n",
    "\n",
    "\n",
    "    def evaluate_performance(self, val_loader):\n",
    "\n",
    "        loss_function = nn.CrossEntropyLoss()\n",
    "        self.model.to(device)\n",
    "        self.model.eval()\n",
    "\n",
    "        val_loss = 0.0\n",
    "        total_predictions = 0.0\n",
    "        correct_predictions = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (img, label) in enumerate(val_loader):\n",
    "                \n",
    "                img = img.to(device)\n",
    "                label = label.to(device)\n",
    "                outputs = self.model(img)\n",
    "                loss = loss_function(outputs, label).detach()\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                predicted = torch.argmax(outputs, 1)\n",
    "                total_predictions += img.size(0)\n",
    "                correct_predictions += (predicted == label).sum().item()\n",
    "\n",
    "        val_loss /= len(val_loader) \n",
    "        acc = correct_predictions/total_predictions\n",
    "        \n",
    "        return val_loss, acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from axa_hw2p2.datasets import FaceClassificationDataset, FaceVerificationDataset\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "sample = np.array(range(20))\n",
    "train_dataset = FaceClassificationDataset(sample, mode='train')\n",
    "val_dataset = FaceClassificationDataset(sample, mode='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Architecture parameters\n",
    "mc = {}\n",
    "mc['n_ch_input'] = 3\n",
    "mc['n_classes'] = len(np.unique([t[1] for t in train_dataset]))\n",
    "\n",
    "# Optimization and regularization parameters\n",
    "mc['batch_size'] = 1\n",
    "mc['lr'] = 0.001\n",
    "mc['lr_decay'] = 1\n",
    "mc['n_lr_decay_steps'] = 2\n",
    "mc['n_epochs'] = 16\n",
    "mc['eval_steps'] = 4\n",
    "\n",
    "print(77*'=')\n",
    "print(pd.Series(mc))\n",
    "print(77*'=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FaceClassificationCNN(n_ch_input=mc['n_ch_input'],\n",
    "                              n_classes=mc['n_classes'],\n",
    "                              lr=mc['lr'],\n",
    "                              lr_decay=float(mc['lr_decay']),\n",
    "                              n_lr_decay_steps=int(mc['n_lr_decay_steps']),\n",
    "                              n_epochs=mc['n_epochs'],\n",
    "                              eval_steps=mc['eval_steps'])\n",
    "print(model.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, \n",
    "                          shuffle=True, \n",
    "                          batch_size=mc['batch_size'], \n",
    "                          drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, \n",
    "                        shuffle=False, \n",
    "                        batch_size=mc['batch_size'], \n",
    "                        drop_last=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_loader=train_loader, val_loader=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idl_ubuntu",
   "language": "python",
   "name": "idl_ubuntu"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
